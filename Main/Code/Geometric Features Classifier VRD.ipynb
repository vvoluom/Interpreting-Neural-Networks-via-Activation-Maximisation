{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(shape,mlb,BS,model,NUM_TEST_IMAGES,testLabels,TEST_CSV,number):\n",
    "    # re-initialize our testing data generator, this time for evaluating\n",
    "    testGen = csv_image_generator_multilabel_predictor(shape,TEST_CSV, BS)\n",
    "    #predict_generator(generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "    print(\"RUNNING PREDICTIONS\")\n",
    "    predictions = model.predict_generator(testGen, steps=NUM_TEST_IMAGES/1,workers=1,use_multiprocessing=True ,verbose=1)\n",
    "    write_Accuracy(predictions,testLabels,number,mlb)\n",
    "    predictions = []\n",
    "    Y_Test = []\n",
    "    \n",
    "def write_Accuracy(predictions,Y_Test,number,mlb):\n",
    "    recalls = get_recalls_for_k(predictions,Y_Test,4,len(mlb.classes_))\n",
    "    \n",
    "    row = [\"Classes\",\"k = 1 \",\"k = 2\",\"k = 3\",\"k = 4\"]\n",
    "    rows = []\n",
    "    rows.append(row)\n",
    "    for i in range(len(mlb.classes_)):\n",
    "        row  = [mlb.classes_[i],recalls[0][i],recalls[1][i],recalls[2][i],recalls[3][i]]\n",
    "        rows.append(row)    \n",
    "    \n",
    "    rows.append([\"Micro AVG\",sum(recalls[0])/len(recalls[0]),sum(recalls[1])/len(recalls[1]),sum(recalls[2])/len(recalls[2]),sum(recalls[3])/len(recalls[3])])\n",
    "    location = \"GeometricReports/\"+str(number)+\".csv\"\n",
    "    with open(location,\"a\",newline=\"\") as f1: \n",
    "        cw = csv.writer(f1)\n",
    "        cw.writerows(rows)\n",
    "    f1.close()\n",
    "    recalls = []\n",
    "    rows = []\n",
    "    predictions = []\n",
    "    Y_Test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_count_1(a):\n",
    "    m = len(a)\n",
    "    y_count = []\n",
    "    for i in range(m):\n",
    "        #print(a[i])\n",
    "        if a[i] == 1:\n",
    "            y_count.append(i)\n",
    "    return y_count\n",
    "\n",
    "def get_pred_rank1(a):\n",
    "    N=len(a)\n",
    "    b=np.zeros([N],dtype=[('prob',float),('idx',int)])\n",
    "    #for i in range(N)\n",
    "    b['idx']=np.arange(N)\n",
    "    b['prob']=np.copy(a)\n",
    "    b.sort(order='prob')\n",
    "    return b\n",
    "\n",
    "def TP_FN(y_pred,y_test,k):\n",
    "    TP = []\n",
    "    FN = []\n",
    "    for j in range(len(y_pred)):\n",
    "        Y = y_test[j]\n",
    "        H = get_pred_rank1(y_pred[j])        \n",
    "        y_count = y_count_1(y_test[j])\n",
    "        y_rank = np.flip(np.asarray(H['idx'],dtype=int),0) \n",
    "        #print(y_rank)\n",
    "        for p in y_count:\n",
    "            if p in y_rank[:k]:\n",
    "                TP.append(p)\n",
    "            else:\n",
    "                #print(p)\n",
    "                FN.append(p)\n",
    "            \n",
    "    return TP,FN \n",
    "\n",
    "def get_per_label(TP,FN,n):\n",
    "    Recalls = []\n",
    "    for i in range(0,n):\n",
    "        TP1 = TP.get(i)\n",
    "        FN1 = FN.get(i)\n",
    "        if TP1 == None:\n",
    "            TP1 = 0\n",
    "        if FN1 == None:\n",
    "            FN1 = 0\n",
    "                \n",
    "        if (TP1+FN1) == 0:\n",
    "            Recall = 0\n",
    "        else:\n",
    "            Recall  = (TP1)/(TP1+FN1)\n",
    "            \n",
    "        Recalls.append(Recall)\n",
    "        \n",
    "    return Recalls\n",
    "\n",
    "#Recall => TP/TP+FN\n",
    "def get_recalls_for_k(predictions,Y_Test,k,n):\n",
    "    ALL_Recalls = []\n",
    "    for i in range(k): \n",
    "        TP,FN  = TP_FN(predictions,Y_Test,i+1)\n",
    "        TP_Counter = Counter(TP)\n",
    "        FN_Counter = Counter(FN)\n",
    "        Recall = get_per_label(TP_Counter,FN_Counter,n)\n",
    "        ALL_Recalls.append(Recall)\n",
    "    return ALL_Recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_labels(a,p,k):\n",
    "    #a is the list of percentages in order \n",
    "    #p is the percentage cut off point e.g 50%\n",
    "    #k is the top k answers to take\n",
    "    pred_l = []\n",
    "    temp_index = []\n",
    "    count = 0\n",
    "    m = len(a)\n",
    "    a = a.tolist()\n",
    "    for i in a:\n",
    "        if count <= k and (max(a)*100) >= p:\n",
    "            highest = max(a)\n",
    "            temp_index.append(a.index(highest))\n",
    "            a.remove(highest)\n",
    "            count += 1 \n",
    "    for i in range(m):\n",
    "        pred_l.append(0)\n",
    "    for j in range(len(temp_index)):\n",
    "        pred_l[temp_index[j]] = 1\n",
    "                \n",
    "    return pred_l\n",
    "\n",
    "def prediction_labels_FCFS(a,p,k):\n",
    "    #a is the list of percentages in order \n",
    "    #p is the percentage cut off point e.g 50%\n",
    "    #k is the top k answers to take\n",
    "    pred_l = []\n",
    "    temp_top = []\n",
    "    count = 0\n",
    "    #Problem this is FCFS\n",
    "    for i in range(len(a)):\n",
    "        if (a[i]*100) >= p and count <= k:\n",
    "            count += 1\n",
    "            pred_l.append(1)\n",
    "        elif (a[i]*100) <= p:\n",
    "            pred_l.append(0)\n",
    "        else:\n",
    "            pred_l.append(0)\n",
    "    return pred_l\n",
    "\n",
    "\n",
    "def ordered_intersection(y, h):\n",
    "    lst3 = []\n",
    "    y_count = 0\n",
    "    h_count = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1: \n",
    "            y_count +=1 \n",
    "        if h[i] == 1:\n",
    "            h_count +=1 \n",
    "        if y[i] == h[i] and y[i] == 1:\n",
    "            lst3.append(y[i])\n",
    "    return lst3 , y_count,h_count\n",
    "\n",
    "#https://stackoverflow.com/questions/9004172/precision-recall-for-multiclass-multilabel-classification\n",
    "#Example based Metrics for Precision and Recall\n",
    "def precision_recall(y_pred,y_test):\n",
    "    pres = []\n",
    "    rec  = []\n",
    "    acc  = []\n",
    "    n = len(y_pred)\n",
    "    for i in range(len(y_pred)):\n",
    "        lst3 , y_count,h_count = ordered_intersection(y_test[i], y_pred[i])\n",
    "        if h_count == 0:\n",
    "            pres.append(0)\n",
    "            rec.append((len(lst3)/y_count))\n",
    "        elif y_count == 0:\n",
    "            pres.append((len(lst3)/h_count))\n",
    "            rec.append(0)\n",
    "        else:\n",
    "            pres.append((len(lst3)/h_count))\n",
    "            rec.append((len(lst3)/y_count))\n",
    "        acc.append(len(lst3)/(y_count+h_count))\n",
    "        \n",
    "    precision = sum(pres)/n\n",
    "    recall = sum(rec)/n\n",
    "    accuracy = sum(acc)/n\n",
    "    B = 1 \n",
    "    F1 = ((1+B**2)*precision*recall)/((B**2)*precision+recall)\n",
    "    \n",
    "    return precision,recall,accuracy,F1\n",
    "\n",
    "def TP_FP_TN_FN(y_pred,y_test):\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    \n",
    "    for j in range(len(y_pred)):\n",
    "        H = y_pred[j]\n",
    "        Y = y_test[j]\n",
    "\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i] == H[i] and Y[i] == 1:\n",
    "                TP.append(i)\n",
    "            elif Y[i] != H[i]:\n",
    "                if Y[i] == 1:\n",
    "                    FN.append(i)\n",
    "                elif H[i] == 1:\n",
    "                    FP.append(i)\n",
    "            elif Y[i] == H[i] and Y[i] == 0:\n",
    "                TN.append(i)\n",
    "                \n",
    "    return TP,FP,TN,FN\n",
    "    \n",
    "def Macro_Labels(TP,FP,TN,FN,n):\n",
    "    Accuracies = []\n",
    "    Precisions = []\n",
    "    Recalls    = []\n",
    "    F1s        = []\n",
    "    B = 1 \n",
    "    for i in range(0,n):\n",
    "        TP1 = TP.get(i)\n",
    "        FP1 = FP.get(i)\n",
    "        TN1 = TN.get(i)\n",
    "        FN1 = FN.get(i)\n",
    "        #print(TP1,FP1,TN1,FN1)\n",
    "        for i1 in range(4):\n",
    "            if TP1 == None:\n",
    "                TP1 = 0\n",
    "            elif FP1 == None:\n",
    "                FP1 = 0\n",
    "            elif TN1 == None:\n",
    "                TN1 = 0\n",
    "            elif FN1 == None:\n",
    "                FN1 = 0\n",
    "        \n",
    "        if (TP1+FP1+TN1+FN1) == 0:\n",
    "            Accuracy = 0\n",
    "        else:\n",
    "            Accuracy  = (TP1+TN1)/(TP1+FP1+TN1+FN1)\n",
    "        \n",
    "        if (TP1+FP1) == 0:\n",
    "            Precision = 0\n",
    "        else:\n",
    "            Precision = (TP1)/(TP1+FP1)\n",
    "        \n",
    "        if (TP1+FN1) == 0:\n",
    "            Recall = 0\n",
    "        else:\n",
    "            Recall    = (TP1)/(TP1+FN1)\n",
    "        \n",
    "        if ((1+B**2)*TP1+(B**2+FN1)+FP1) == 0:\n",
    "            F1 = 0\n",
    "        else:\n",
    "            F1  = (TP1*(1+(B**2)))/((1+B**2)*TP1+(B**2+FN1)+FP1)\n",
    "        \n",
    "        Accuracies.append(Accuracy)\n",
    "        Precisions.append(Precision)\n",
    "        Recalls.append(Recall)\n",
    "        F1s.append(F1)\n",
    "        \n",
    "        Ma_Acc  = sum(Accuracies)/n\n",
    "        Ma_Pres = sum(Precisions)/n\n",
    "        Ma_Rec  = sum(Recalls)/n\n",
    "        Ma_F1     = sum(F1s)/n\n",
    "    \n",
    "    return Ma_Acc,Ma_Pres,Ma_Rec,Ma_F1\n",
    "\n",
    "def Micro_Labels(TP,FP,TN,FN,n):\n",
    "    B = 1\n",
    "    All_TP = []\n",
    "    All_FP = []\n",
    "    All_TN = []\n",
    "    All_FN = []\n",
    "\n",
    "    for i in range(0,n):\n",
    "        TP1 = TP.get(i)\n",
    "        FP1 = FP.get(i)\n",
    "        TN1 = TN.get(i)\n",
    "        FN1 = FN.get(i)\n",
    "        #print(TP1,FP1,TN1,FN1)\n",
    "        for i1 in range(4):\n",
    "            if TP1 == None:\n",
    "                TP1 = 0\n",
    "            elif FP1 == None:\n",
    "                FP1 = 0\n",
    "            elif TN1 == None:\n",
    "                TN1 = 0\n",
    "            elif FN1 == None:\n",
    "                FN1 = 0\n",
    "\n",
    "        All_TP.append(TP1)\n",
    "        All_FP.append(FP1)\n",
    "        All_TN.append(TN1)\n",
    "        All_FN.append(FN1)\n",
    "\n",
    "    TP1 = sum(All_TP)\n",
    "    FP1 = sum(All_FP)\n",
    "    TN1 = sum(All_TN)\n",
    "    FN1 = sum(All_FN)\n",
    "\n",
    "    if (TP1+FP1+TN1+FN1) == 0:\n",
    "        Accuracy = 0\n",
    "    else:\n",
    "        Accuracy  = (TP1+TN1)/(TP1+FP1+TN1+FN1)\n",
    "\n",
    "    if (TP1+FP1) == 0:\n",
    "        Precision = 0\n",
    "    else:\n",
    "        Precision = (TP1)/(TP1+FP1)\n",
    "\n",
    "    if (TP1+FN1) == 0:\n",
    "        Recall = 0\n",
    "    else:\n",
    "        Recall    = (TP1)/(TP1+FN1)\n",
    "\n",
    "    if ((1+B**2)*TP1+(B**2+FN1)+FP1) == 0:\n",
    "        F1 = 0\n",
    "    else:\n",
    "        F1 = (TP1*(1+(B**2)))/((1+B**2)*TP1+(B**2+FN1)+FP1)\n",
    "\n",
    "    Mi_Acc = Accuracy\n",
    "    Mi_Pres = Precision\n",
    "    Mi_Rec = Recall\n",
    "    Mi_F1 = F1\n",
    "\n",
    "    return Mi_Acc,Mi_Pres,Mi_Rec,Mi_F1\n",
    "\n",
    "def get_per_label1(TP,FP,TN,FN,n):\n",
    "    B = 1\n",
    "    Accuracies = []\n",
    "    Precisions = []\n",
    "    Recalls    = []\n",
    "    F1s        = []\n",
    "    for i in range(0,n):\n",
    "        TP1 = TP.get(i)\n",
    "        FP1 = FP.get(i)\n",
    "        TN1 = TN.get(i)\n",
    "        FN1 = FN.get(i)\n",
    "        #print(TP1,FP1,TN1,FN1)\n",
    "        for i1 in range(4):\n",
    "            if TP1 == None:\n",
    "                TP1 = 0\n",
    "            elif FP1 == None:\n",
    "                FP1 = 0\n",
    "            elif TN1 == None:\n",
    "                TN1 = 0\n",
    "            elif FN1 == None:\n",
    "                FN1 = 0\n",
    "\n",
    "        if (TP1+FP1+TN1+FN1) == 0:\n",
    "            Accuracy = 0\n",
    "        else:\n",
    "            Accuracy  = (TP1+TN1)/(TP1+FP1+TN1+FN1)\n",
    "\n",
    "        if (TP1+FP1) == 0:\n",
    "            Precision = 0\n",
    "        else:\n",
    "            Precision = (TP1)/(TP1+FP1)\n",
    "\n",
    "        if (TP1+FN1) == 0:\n",
    "            Recall = 0\n",
    "        else:\n",
    "            Recall    = (TP1)/(TP1+FN1)\n",
    "\n",
    "        if ((1+B**2)*TP1+(B**2+FN1)+FP1) == 0:\n",
    "            F1 = 0\n",
    "        else:\n",
    "            F1 = (TP1*(1+(B**2)))/((1+B**2)*TP1+(B**2+FN1)+FP1)\n",
    "        \n",
    "        #print(Accuracy,Precision,Recall,F1)\n",
    "        Accuracies.append(Accuracy)\n",
    "        Precisions.append(Precision)\n",
    "        Recalls.append(Recall)\n",
    "        F1s.append(F1)\n",
    "    \n",
    "    return Accuracies,Precisions,Recalls,F1s\n",
    "    \n",
    "    \n",
    "def get_recall_at_K_Example(y_pred,y_test,k,p,n):\n",
    "    predictions = []\n",
    "    predictions2 = []\n",
    "    for i in range(len(y_test)):\n",
    "        pred_l = prediction_labels(y_pred[i],p,k)\n",
    "        predictions.append(pred_l)\n",
    "    \n",
    "    TP,FP,TN,FN = TP_FP_TN_FN(predictions,y_test)\n",
    "    TP_Counter = Counter(TP)\n",
    "    FP_Counter = Counter(FP)\n",
    "    TN_Counter = Counter(TN)\n",
    "    FN_Counter = Counter(FN)\n",
    "\n",
    "    Ma_Acc,Ma_Pres,Ma_Rec,Ma_F1 = Macro_Labels(TP_Counter,FP_Counter,TN_Counter,FN_Counter,n)\n",
    "    Mi_Acc,Mi_Pres,Mi_Rec,Mi_F1 = Micro_Labels(TP_Counter,FP_Counter,TN_Counter,FN_Counter,n)\n",
    "    Accuracies,Precisions,Recalls,F1s = get_per_label(TP_Counter,FP_Counter,TN_Counter,FN_Counter,n)\n",
    "    ex_precision,ex_recall,ex_accuracy,ex_F1 = precision_recall(predictions,y_test)\n",
    "    \n",
    "    return Accuracies,Precisions,Recalls,F1s,Mi_Acc,Mi_Pres,Mi_Rec,Mi_F1,ex_precision,ex_recall,ex_accuracy,ex_F1,Ma_Acc,Ma_Pres,Ma_Rec,Ma_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def write_Accuracy(predictions,Y_Test,k,p,number,mlb):\n",
    "#    Accuracies,Precisions,Recalls,F1s,Mi_Acc,Mi_Pres,Mi_Rec,Mi_F1,ex_precision,ex_recall,ex_accuracy,ex_F1,Ma_Acc,Ma_Pres,Ma_Rec,Ma_F1 = get_recall_at_K_Example(predictions,Y_Test,k,p,len(mlb.classes_))#\n",
    "\n",
    "#    row = [\"Classes\",\"Accuracy\",\"Precision\",\"Recall\",\"F1-Score\"]\n",
    "#    rows = []\n",
    "#    rows.append(row)\n",
    "#    for i in range(len(mlb.classes_)):\n",
    "#        row  = [mlb.classes_[i],Accuracies[i],Precisions[i],Recalls[i],F1s[i]]\n",
    "#        rows.append(row)    \n",
    "#    \n",
    "#    rows.append([\"MACRO AVG\",Ma_Acc,Ma_Pres,Ma_Rec,Ma_F1])\n",
    "#    rows.append([\"Micro AVG\",Mi_Acc,Mi_Pres,Mi_Rec,Mi_F1])\n",
    "#    rows.append([\"EXAMPLES\",ex_accuracy,ex_precision,ex_recall,ex_F1])\n",
    "#    location = \"GeometricReports/\"+str(number)+\".csv\"\n",
    "#    with open(location,\"a\",newline=\"\") as f1: \n",
    "#        cw = csv.writer(f1)\n",
    "#        cw.writerows(rows)\n",
    "#    f1.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_generator_OLD(X_Train,Y_Train,bs,mlb,mode):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_features = []\n",
    "        y_features = []\n",
    "        x = 0 \n",
    "        while x < bs:\n",
    "            if i >= len(X_Train):\n",
    "                i = 0\n",
    "                if mode == \"eval\":\n",
    "                    break\n",
    "            if i < len(X_Train):\n",
    "                x_features.append(X_Train[i])\n",
    "                y_features.append(Y_Train[i])\n",
    "                i+=1\n",
    "            else:\n",
    "                i+=1\n",
    "                continue\n",
    "            x +=1\n",
    "            \n",
    "        y_features = np.array(y_features)\n",
    "        y_features = mlb.transform(y_features)\n",
    "        yield(np.array(x_features),y_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoder(train_path_geo,test_path_geo,valid_path_geo):\n",
    "    #Read the list \n",
    "    with open(train_path_geo, 'r') as f1:\n",
    "        reader = csv.reader(f1)\n",
    "        your_list = list(reader)\n",
    "    f1.close()\n",
    "\n",
    "    #Read the list \n",
    "    with open(test_path_geo, 'r') as f1:\n",
    "        reader = csv.reader(f1)\n",
    "        your_list_test = list(reader)\n",
    "    f1.close()\n",
    "\n",
    "    #Read the list \n",
    "    with open(valid_path_geo, 'r') as f1:\n",
    "        reader = csv.reader(f1)\n",
    "        your_list_valid = list(reader)\n",
    "    f1.close()\n",
    "    \n",
    "    #Encoders\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    enc_category = OneHotEncoder()\n",
    "\n",
    "    C_Train = []\n",
    "    X_Train = []\n",
    "    Y_Train = []\n",
    "    for i in range(len(your_list)):\n",
    "        y1 = ast.literal_eval(your_list[i][0])\n",
    "        y1 = [n.strip() for n in y1]\n",
    "        Y_Train.append(y1)\n",
    "        \n",
    "        g2 = your_list[i][1]\n",
    "        g3 = your_list[i][2]\n",
    "        C_Train.append([g2,g3])\n",
    "        x1 = [float(your_list[i][3]),float(your_list[i][4]),float(your_list[i][5]),\n",
    "              float(your_list[i][6]),float(your_list[i][7]),float(your_list[i][8]),\n",
    "              float(your_list[i][10]),float(your_list[i][11]),float(your_list[i][12]),\n",
    "              float(your_list[i][13]),float(your_list[i][14]),float(your_list[i][15])]\n",
    "        X_Train.append(x1)\n",
    "        \n",
    "    del your_list[:]\n",
    "\n",
    "    C_Test = []\n",
    "    X_Test = []\n",
    "    Y_Test = []\n",
    "    for i in range(len(your_list_test)):\n",
    "        y1 = ast.literal_eval(your_list_test[i][0])\n",
    "        y1 = [n.strip() for n in y1]\n",
    "        Y_Test.append(y1)\n",
    "        \n",
    "        g2 = your_list_test[i][1]\n",
    "        g3 = your_list_test[i][2]\n",
    "        C_Test.append([g2,g3])\n",
    "\n",
    "    del your_list_test[:]\n",
    "\n",
    "    C_Valid = []\n",
    "    Y_Valid = []\n",
    "    for i in range(len(your_list_valid)):\n",
    "        y1 = ast.literal_eval(your_list_valid[i][0])\n",
    "        y1 = [n.strip() for n in y1]\n",
    "        Y_Valid.append(y1)\n",
    "\n",
    "        g2 = your_list_valid[i][1]\n",
    "        g3 = your_list_valid[i][2]\n",
    "        C_Valid.append([g2,g3])\n",
    "\n",
    "    del your_list_valid[:]\n",
    "    #Fitting the data\n",
    "    Out =  C_Train+C_Test+C_Valid\n",
    "    enc_category.fit(Out)\n",
    "    mlb.fit(Y_Train)\n",
    "    mlb.fit(Y_Valid)\n",
    "    mlb.fit(Y_Test)\n",
    "    min_max_scaler.fit(X_Train)\n",
    "    \n",
    "    TX = len(X_Train)\n",
    "    TV = len(Y_Valid)\n",
    "    TT = len(Y_Test)\n",
    "    del Out[:]\n",
    "    \n",
    "    return enc_category,min_max_scaler,mlb,TX,TV,TT,Y_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_generator(inputPath, bs, mlb,enc_category,min_max_scaler):\n",
    "    \n",
    "    enc_compass = OneHotEncoder()\n",
    "    enc_compass.fit([[\"North\"],[\"East\"],[\"South\"],[\"West\"]])\n",
    "    # open the CSV file for reading\n",
    "    f = open(inputPath, \"r\")\n",
    "    while True:\n",
    "\n",
    "        # initialize our batches of images and labels\n",
    "        x_features = []\n",
    "        y_features = []\n",
    "        while len(x_features) < bs:\n",
    "\n",
    "            X_Train = []\n",
    "            E_Train = []\n",
    "            C_Train = []\n",
    "            \n",
    "            line = f.readline()\n",
    "            if line == \"\":\n",
    "                f.seek(0)\n",
    "                line = f.readline()\n",
    "\n",
    "            empty_string = \"\"\n",
    "            comma_counter = 1\n",
    "            for x in line.rstrip():\n",
    "                if x == \"\\\"\":\n",
    "                    continue\n",
    "                elif x == \",\":\n",
    "                    comma_counter += 1\n",
    "                    empty_string = empty_string+x\n",
    "                elif x == \"]\":\n",
    "                    empty_string = empty_string+x\n",
    "                    break\n",
    "                else:\n",
    "                    empty_string = empty_string+x\n",
    "            \n",
    "            line = line.strip().split(\",\")\n",
    "            x_feature = [x1 for x1 in line[comma_counter:]]\n",
    "\n",
    "            y1 = ast.literal_eval(empty_string)\n",
    "            y1 = [n for n in y1]\n",
    "            y_features.append(y1)\n",
    "\n",
    "            g1 = enc_compass.transform([[x_feature[8]]]).toarray()\n",
    "            g2 = x_feature[0]\n",
    "            g3 = x_feature[1]\n",
    "            C_Train.append([g2,g3])\n",
    "            x1 = [float(x_feature[2]),float(x_feature[3]),float(x_feature[4]),\n",
    "                  float(x_feature[5]),float(x_feature[6]),float(x_feature[7]),\n",
    "                  float(x_feature[9]),float(x_feature[10]),float(x_feature[11]),\n",
    "                  float(x_feature[12]),float(x_feature[13]),float(x_feature[14])]\n",
    "\n",
    "            X_Train.append(x1)\n",
    "            X_Train = min_max_scaler.transform(X_Train)\n",
    "            C_Train = enc_category.transform(C_Train).toarray()\n",
    "            E_Train.append(g1[0])\n",
    "\n",
    "            X_Train = np.concatenate([X_Train, E_Train,C_Train], axis=1) \n",
    "            x_features.append(X_Train[0])\n",
    "\n",
    "        y_features = np.array(y_features)\n",
    "        y_features = mlb.transform(y_features)\n",
    "        yield(np.array(x_features),y_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_generator_test(inputPath, bs, mlb,enc_category,min_max_scaler):\n",
    "    \n",
    "    enc_compass = OneHotEncoder()\n",
    "    enc_compass.fit([[\"North\"],[\"East\"],[\"South\"],[\"West\"]])\n",
    "    # open the CSV file for reading\n",
    "    f = open(inputPath, \"r\")\n",
    "    i = 0\n",
    "    while True:\n",
    "\n",
    "        # initialize our batches of images and labels\n",
    "        x_features = []\n",
    "        while len(x_features) < 1:\n",
    "            X_Train = []\n",
    "            E_Train = []\n",
    "            C_Train = []\n",
    "            \n",
    "            line = f.readline()\n",
    "            #if line == \"\":\n",
    "            #    f.seek(0)\n",
    "            #    line = f.readline()\n",
    "\n",
    "            empty_string = \"\"\n",
    "            comma_counter = 1\n",
    "            for x in line.rstrip():\n",
    "                if x == \"\\\"\":\n",
    "                    continue\n",
    "                elif x == \",\":\n",
    "                    comma_counter += 1\n",
    "                    empty_string = empty_string+x\n",
    "                elif x == \"]\":\n",
    "                    empty_string = empty_string+x\n",
    "                    break\n",
    "                else:\n",
    "                    empty_string = empty_string+x\n",
    "\n",
    "            line = line.strip().split(\",\")\n",
    "            x_feature = [x1 for x1 in line[comma_counter:]]\n",
    "\n",
    "            g1 = enc_compass.transform([[x_feature[8]]]).toarray()\n",
    "            g2 = x_feature[0]\n",
    "            g3 = x_feature[1]\n",
    "            C_Train.append([g2,g3])\n",
    "            x1 = [float(x_feature[2]),float(x_feature[3]),float(x_feature[4]),\n",
    "                  float(x_feature[5]),float(x_feature[6]),float(x_feature[7]),\n",
    "                  float(x_feature[9]),float(x_feature[10]),float(x_feature[11]),\n",
    "                  float(x_feature[12]),float(x_feature[13]),float(x_feature[14])]\n",
    "\n",
    "            X_Train.append(x1)\n",
    "            X_Train = min_max_scaler.transform(X_Train)\n",
    "            C_Train = enc_category.transform(C_Train).toarray()\n",
    "            E_Train.append(g1[0])\n",
    "\n",
    "            X_Train = np.concatenate([X_Train, E_Train,C_Train], axis=1) \n",
    "            x_features.append(X_Train[0])\n",
    "\n",
    "        yield(np.array(x_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_10_geometric():\n",
    "    for number in range(0,10):\n",
    "        train_path_geo =  \"Voc2kGeometric/Training_data_\"+str(number)+\".csv\"\n",
    "        test_path_geo =  \"Voc2kGeometric/Testing_data_\"+str(number)+\".csv\"\n",
    "        valid_path_geo =  \"Voc2kGeometric/Validation_data_\"+str(number)+\".csv\"\n",
    "        bs = 32\n",
    "        enc_category,min_max_scaler,mlb,TX,TV,TT,Y_Test =  get_category_encoder(train_path_geo,test_path_geo,valid_path_geo)\n",
    "        \n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(2048, init=\"uniform\",activation='relu', input_shape=(168,)),\n",
    "            Dense(1024, kernel_initializer=\"uniform\" ,activation='relu'),\n",
    "            Dense(len(mlb.classes_), activation='sigmoid'),\n",
    "        ])\n",
    "        \n",
    "        trainGen = csv_generator(train_path_geo, bs, mlb,enc_category,min_max_scaler)\n",
    "        valGen   = csv_generator(valid_path_geo, bs, mlb,enc_category,min_max_scaler)\n",
    "        #testGen  = csv_generator(test_path_geo, bs, mlb,enc_category,min_max_scaler)\n",
    "        testGen  = csv_generator_test(test_path_geo, bs, mlb,enc_category,min_max_scaler)\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['categorical_accuracy'])\n",
    "\n",
    "        hist = model.fit_generator(trainGen, steps_per_epoch = (TX/32)-1,validation_data=valGen, validation_steps=(TV/32)-1,epochs=5)\n",
    "        model_name = \"GeometricModels/sv\"+str(number)+\"5_.h5\"\n",
    "        model.save(model_name)\n",
    "        #evaluate_model(shape,mlb,BS,model,NUM_TEST_IMAGES,testLabels,TEST_CSV,number)\n",
    "        #print(\"RUNNING PREDICTIONS\")\n",
    "        predictions = model.predict_generator(testGen, steps=TT/1,workers=1,use_multiprocessing=True, verbose=1)\n",
    "        Y_Test = mlb.transform(Y_Test)\n",
    "        #write_Accuracy(predictions,Y_Test,5,50,number,mlb)\n",
    "        write_Accuracy(predictions,Y_Test,number,mlb)\n",
    "        K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuclearvodka/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2048, activation=\"relu\", input_shape=(168,), kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "['derriere', 'pres_de']\n",
      "['derriere', 'pres_de']['devant', 'loin_de']\n",
      "\n",
      "['devant', 'a_cote_de', 'pres_de']['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['sous']\n",
      "['derriere', 'pres_de']\n",
      "['derriere']\n",
      "['sous', 'contre']\n",
      "['au_niveau_de', 'pres_de']\n",
      "['derriere']['sur', 'contre']\n",
      "\n",
      "['au_niveau_de']\n",
      "['devant']['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['en_face_de', 'pres_de']\n",
      "['derriere']\n",
      "['derriere', 'devant']['derriere', 'pres_de']\n",
      "\n",
      "['sous']['derriere', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['derriere', 'pres_de']\n",
      "['devant', 'contre']\n",
      "['au_dessus_de', 'a_cote_de', 'pres_de']['devant', 'pres_de']\n",
      "\n",
      "['loin_de']['sur']\n",
      "\n",
      "['derriere', 'contre']\n",
      "['pres_de', 'devant']\n",
      "['sur', 'contre']['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['sur', 'contre']\n",
      "['pres_de', 'a_cote_de']['sur']\n",
      "\n",
      "['sur']\n",
      "['devant', 'derriere']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['pres_de', 'au_niveau_de']\n",
      "['derriere', 'en_face_de']\n",
      "['derriere', 'pres_de']\n",
      "['devant', 'loin_de']['devant', 'pres_de']\n",
      "\n",
      "['derriere', 'pres_de']\n",
      "['a_cote_de', 'derriere', 'pres_de']\n",
      "['devant']['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['sur']['sous']\n",
      "\n",
      "['aucun']['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['sous']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['devant', 'loin_de']\n",
      "['devant']\n",
      "['derriere', 'pres_de']\n",
      "['pres_de', 'devant']\n",
      "['sous']\n",
      "['derriere', 'loin_de']['derriere', 'a_cote_de', 'pres_de']\n",
      "['sous', 'a_cote_de', 'pres_de']\n",
      "['derriere']\n",
      "\n",
      "['devant']['a_cote_de', 'devant', 'pres_de']\n",
      "\n",
      "['devant', 'loin_de']['a_cote_de', 'contre']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['en_face_de', 'pres_de']['dans']\n",
      "\n",
      "['sous']['a_cote_de', 'devant', 'pres_de']\n",
      "\n",
      "['a_cote_de', 'devant', 'pres_de']\n",
      "['pres_de', 'devant']\n",
      "['sur', 'contre', 'devant']\n",
      "['sur', 'contre']['sur', 'contre']\n",
      "\n",
      "['derriere']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'devant', 'pres_de']['derriere', 'pres_de']\n",
      "['sur', 'contre']\n",
      "\n",
      "['a_cote_de', 'au_niveau_de']['a_cote_de', 'derriere']\n",
      "\n",
      "['en_face_de', 'au_dessus_de']\n",
      "['devant', 'loin_de']\n",
      "['a_cote_de', 'au_niveau_de', 'en_face_de', 'pres_de']\n",
      "['contre', 'sur']['devant', 'derriere']\n",
      "\n",
      "['devant', 'a_cote_de', 'au_dessus_de']['a_cote_de', 'au_niveau_de', 'devant']\n",
      "\n",
      "['pres_de', 'au_niveau_de']['devant', 'contre']\n",
      "\n",
      "['autour_de']['loin_de']\n",
      "\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']['pres_de', 'a_cote_de', 'au_niveau_de']\n",
      "\n",
      "['sous']['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['aucun']['pres_de', 'a_cote_de', 'au_dessus_de']\n",
      "\n",
      "['en_face_de', 'devant', 'pres_de']\n",
      "['sous']['pres_de']\n",
      "\n",
      "['sur']\n",
      "['pres_de', 'devant']\n",
      "['devant', 'pres_de']['pres_de', 'a_cote_de']\n",
      "\n",
      "['pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['sur']['devant', 'loin_de']\n",
      "\n",
      "['pres_de', 'devant']\n",
      "['derriere', 'loin_de']\n",
      "['derriere', 'contre', 'pres_de']\n",
      "['a_cote_de', 'pres_de']\n",
      "['pres_de', 'derriere']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'pres_de']['devant', 'loin_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['au_dessus_de', 'pres_de']\n",
      "['devant', 'loin_de']['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['en_face_de', 'derriere']\n",
      "['sous']['a_cote_de', 'derriere', 'le_long_de', 'pres_de']\n",
      "['devant']\n",
      "\n",
      "['au_dessus_de', 'pres_de']['aucun']\n",
      "\n",
      "['autour_de']['devant', 'derriere', 'pres_de']\n",
      "\n",
      "['sur']['sur', 'contre']\n",
      "['a_cote_de', 'pres_de']\n",
      "\n",
      "['a_cote_de', 'au_niveau_de', 'le_long_de', 'pres_de']\n",
      "['devant', 'a_cote_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'devant', 'pres_de']['devant', 'contre']\n",
      "['devant', 'contre']\n",
      "['devant', 'derriere']\n",
      "['a_cote_de', 'pres_de']\n",
      "['pres_de']\n",
      "\n",
      "['pres_de', 'devant']\n",
      "['devant', 'derriere', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['sous', 'contre']\n",
      "['derriere', 'contre']\n",
      "['a_cote_de', 'au_niveau_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['sous']\n",
      "['en_face_de', 'devant']\n",
      "['derriere', 'pres_de']\n",
      "['a_cote_de', 'devant', 'pres_de']['en_face_de', 'pres_de']\n",
      "\n",
      "['au_niveau_de', 'pres_de']\n",
      "['sur']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['au_niveau_de']\n",
      "['pres_de']['devant', 'loin_de']\n",
      "\n",
      "['pres_de']['sur']\n",
      "\n",
      "['a_cote_de', 'derriere', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'derriere', 'pres_de']\n",
      "['sous', 'contre']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']['devant', 'loin_de']\n",
      "['dans']\n",
      "\n",
      "['devant', 'loin_de']\n",
      "['au_dessus_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['sur', 'contre']['derriere']\n",
      "['devant', 'loin_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['sur', 'contre']\n",
      "\n",
      "['en_face_de', 'devant', 'pres_de']\n",
      "['sous']\n",
      "['a_cote_de']['devant', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "\n",
      "['a_cote_de', 'pres_de']['devant', 'pres_de']\n",
      "\n",
      "['derriere', 'loin_de']\n",
      "['devant', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']['devant', 'contre']\n",
      "['derriere']\n",
      "\n",
      "['derriere']['a_cote_de', 'pres_de']\n",
      "\n",
      "['a_cote_de', 'derriere', 'pres_de']['au_niveau_de', 'pres_de']\n",
      "['derriere']\n",
      "['sous', 'contre']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['devant', 'contre']\n",
      "['devant', 'loin_de']\n",
      "['a_cote_de', 'pres_de']['en_face_de', 'derriere']\n",
      "\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['en_face_de', 'a_cote_de', 'au_niveau_de', 'contre']\n",
      "['en_face_de', 'au_niveau_de', 'pres_de']\n",
      "['sous', 'contre']\n",
      "['derriere', 'contre', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['derriere', 'pres_de']\n",
      "['a_cote_de', 'pres_de']\n",
      "['derriere', 'pres_de']\n",
      "['derriere', 'contre']\n",
      "['a_cote_de', 'au_niveau_de']\n",
      "['derriere', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['derriere', 'pres_de']\n",
      "['derriere']\n",
      "['derriere', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['derriere', 'pres_de']\n",
      "['devant', 'loin_de']\n",
      "['sur']\n",
      "['derriere', 'contre']\n",
      "['derriere']\n",
      "['sur']\n",
      "['loin_de', 'devant']\n",
      "['devant']\n",
      "['dans']\n",
      "['en_face_de', 'devant']\n",
      "['devant', 'a_cote_de', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "['autour_de']\n",
      "['sous']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['en_face_de', 'pres_de']\n",
      "['devant', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'contre']\n",
      "['sous']\n",
      "['a_cote_de', 'derriere', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['sur']\n",
      "['dans']\n",
      "['derriere', 'pres_de']\n",
      "['devant', 'loin_de']\n",
      "['a_cote_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['devant']\n",
      "['a_cote_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['devant', 'au_niveau_de']\n",
      "['devant', 'a_cote_de']\n",
      "['aucun']\n",
      "['devant', 'loin_de']\n",
      "['derriere', 'a_cote_de', 'pres_de']\n",
      "['a_cote_de', 'pres_de']\n",
      "['devant', 'a_cote_de', 'pres_de']\n",
      "['a_cote_de', 'pres_de']\n",
      "['pres_de']\n",
      "['a_cote_de', 'pres_de']\n",
      "['contre', 'sous']\n",
      "['sur', 'contre', 'pres_de']\n",
      "['derriere']\n",
      "['sur', 'contre']\n",
      "['derriere']\n",
      "['devant', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "['derriere', 'a_cote_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['aucun']\n",
      "['devant']\n",
      "['derriere', 'loin_de']\n",
      "['a_cote_de', 'au_niveau_de', 'contre']\n",
      "['au_dessus_de', 'derriere']\n",
      "['en_face_de', 'devant']\n",
      "['derriere', 'pres_de']\n",
      "['devant', 'loin_de']\n",
      "['en_face_de', 'contre', 'devant']\n",
      "['devant', 'pres_de']\n",
      "['sous', 'contre']\n",
      "['devant', 'pres_de']\n",
      "['sous', 'contre']\n",
      "['en_face_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'pres_de']\n",
      "['devant', 'a_cote_de', 'le_long_de', 'pres_de']\n",
      "['sous']\n",
      "['devant', 'pres_de']\n",
      "['a_cote_de', 'devant', 'pres_de']\n",
      "['devant', 'a_cote_de', 'pres_de']\n",
      "['devant', 'loin_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['devant', 'a_cote_de', 'pres_de']\n",
      "['derriere', 'contre']\n",
      "['a_cote_de', 'devant', 'pres_de']\n",
      "['sur', 'contre', 'pres_de']\n",
      "['au_niveau_de', 'a_cote_de']\n",
      "['en_face_de', 'au_niveau_de']\n",
      "['derriere']\n",
      "['derriere']\n",
      "['derriere', 'loin_de']\n",
      "['devant', 'a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "['sur']\n",
      "['a_cote_de', 'au_niveau_de']\n",
      "['devant']\n",
      "['devant']\n",
      "['sous']\n",
      "['derriere', 'loin_de']\n",
      "['devant', 'a_cote_de', 'pres_de']\n",
      "['sous', 'pres_de']\n",
      "['sous', 'contre']\n",
      "['dans', 'sur']\n",
      "['a_cote_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de']\n",
      "['devant']\n",
      "['devant']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['sur', 'contre']\n",
      "['en_face_de', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "['derriere', 'pres_de']\n",
      "['derriere', 'a_cote_de', 'pres_de']\n",
      "['au_niveau_de']\n",
      "['pres_de', 'a_cote_de']\n",
      "['sous', 'a_cote_de', 'pres_de']\n",
      "['derriere', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'en_face_de', 'pres_de']\n",
      "['derriere']\n",
      "['a_cote_de', 'devant', 'pres_de']\n",
      "['derriere', 'contre']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "['derriere']\n",
      "['derriere']\n",
      "['derriere']\n",
      "['contre', 'a_cote_de', 'au_niveau_de']\n",
      "['a_cote_de', 'au_niveau_de', 'contre']\n",
      "['devant', 'pres_de']\n",
      "['pres_de']\n",
      "['a_cote_de', 'pres_de']\n",
      "['sous', 'contre']\n",
      "['devant', 'en_face_de', 'pres_de']\n",
      "['sous']\n",
      "['devant']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['derriere', 'loin_de']\n",
      "['pres_de']\n",
      "['au_niveau_de', 'a_cote_de']\n",
      "['sous', 'contre']\n",
      "['devant']\n",
      "['sur', 'contre']\n",
      "['au_dessus_de', 'derriere']\n",
      "['sous', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'derriere', 'pres_de']\n",
      "['derriere', 'loin_de']\n",
      "['a_cote_de', 'au_dessus_de', 'derriere']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'contre']\n",
      "['derriere']\n",
      "['derriere', 'pres_de']\n",
      "['derriere', 'a_cote_de', 'pres_de']\n",
      "['sous']\n",
      "['devant']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['derriere', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['a_cote_de', 'au_niveau_de', 'contre']\n",
      "['a_cote_de', 'devant', 'pres_de']\n",
      "['derriere', 'pres_de']\n",
      "['derriere']\n",
      "['a_cote_de', 'au_niveau_de', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "['au_dessus_de', 'devant', 'pres_de']\n",
      "['devant', 'pres_de']\n",
      "['devant']\n",
      "['sur']\n",
      "['devant']\n",
      "['devant', 'pres_de']\n",
      "['derriere', 'devant', 'pres_de']\n",
      "['sur', 'contre']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/96 [..............................] - ETA: 1:07 - loss: 0.6942 - categorical_accuracy: 0.0312"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3296\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-40-e8f204f82b10>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    run_10_geometric()\n",
      "  File \u001b[1;32m\"<ipython-input-37-0ac3c3772cdd>\"\u001b[0m, line \u001b[1;32m24\u001b[0m, in \u001b[1;35mrun_10_geometric\u001b[0m\n    hist = model.fit_generator(trainGen, steps_per_epoch = (TX/32)-1,validation_data=valGen, validation_steps=(TV/32)-1,epochs=5)\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\"\u001b[0m, line \u001b[1;32m91\u001b[0m, in \u001b[1;35mwrapper\u001b[0m\n    return func(*args, **kwargs)\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/engine/training.py\"\u001b[0m, line \u001b[1;32m1418\u001b[0m, in \u001b[1;35mfit_generator\u001b[0m\n    initial_epoch=initial_epoch)\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\"\u001b[0m, line \u001b[1;32m181\u001b[0m, in \u001b[1;35mfit_generator\u001b[0m\n    generator_output = next(output_generator)\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\"\u001b[0m, line \u001b[1;32m709\u001b[0m, in \u001b[1;35mget\u001b[0m\n    six.reraise(*sys.exc_info())\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/six.py\"\u001b[0m, line \u001b[1;32m693\u001b[0m, in \u001b[1;35mreraise\u001b[0m\n    raise value\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\"\u001b[0m, line \u001b[1;32m685\u001b[0m, in \u001b[1;35mget\u001b[0m\n    inputs = self.queue.get(block=True).get()\n",
      "  File \u001b[1;32m\"/usr/lib/python3.6/multiprocessing/pool.py\"\u001b[0m, line \u001b[1;32m670\u001b[0m, in \u001b[1;35mget\u001b[0m\n    raise self._value\n",
      "  File \u001b[1;32m\"/usr/lib/python3.6/multiprocessing/pool.py\"\u001b[0m, line \u001b[1;32m119\u001b[0m, in \u001b[1;35mworker\u001b[0m\n    result = (True, func(*args, **kwds))\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\"\u001b[0m, line \u001b[1;32m626\u001b[0m, in \u001b[1;35mnext_sample\u001b[0m\n    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \u001b[1;32m\"<ipython-input-39-12ec9f7b45ef>\"\u001b[0m, line \u001b[1;32m40\u001b[0m, in \u001b[1;35mcsv_generator\u001b[0m\n    y1 = ast.literal_eval(empty_string)\n",
      "  File \u001b[1;32m\"/usr/lib/python3.6/ast.py\"\u001b[0m, line \u001b[1;32m48\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/lib/python3.6/ast.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, PyCF_ONLY_AST)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ['au_niveau_de', a_l'exterieur_de]\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "run_10_geometric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuclearvodka/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2048, activation=\"relu\", input_shape=(168,), kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 1/96 [..............................] - ETA: 1:02 - loss: 0.6912 - categorical_accuracy: 0.1250"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3296\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-42-e8f204f82b10>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    run_10_geometric()\n",
      "  File \u001b[1;32m\"<ipython-input-37-0ac3c3772cdd>\"\u001b[0m, line \u001b[1;32m24\u001b[0m, in \u001b[1;35mrun_10_geometric\u001b[0m\n    hist = model.fit_generator(trainGen, steps_per_epoch = (TX/32)-1,validation_data=valGen, validation_steps=(TV/32)-1,epochs=5)\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\"\u001b[0m, line \u001b[1;32m91\u001b[0m, in \u001b[1;35mwrapper\u001b[0m\n    return func(*args, **kwargs)\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/engine/training.py\"\u001b[0m, line \u001b[1;32m1418\u001b[0m, in \u001b[1;35mfit_generator\u001b[0m\n    initial_epoch=initial_epoch)\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\"\u001b[0m, line \u001b[1;32m181\u001b[0m, in \u001b[1;35mfit_generator\u001b[0m\n    generator_output = next(output_generator)\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\"\u001b[0m, line \u001b[1;32m709\u001b[0m, in \u001b[1;35mget\u001b[0m\n    six.reraise(*sys.exc_info())\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/six.py\"\u001b[0m, line \u001b[1;32m693\u001b[0m, in \u001b[1;35mreraise\u001b[0m\n    raise value\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\"\u001b[0m, line \u001b[1;32m685\u001b[0m, in \u001b[1;35mget\u001b[0m\n    inputs = self.queue.get(block=True).get()\n",
      "  File \u001b[1;32m\"/usr/lib/python3.6/multiprocessing/pool.py\"\u001b[0m, line \u001b[1;32m670\u001b[0m, in \u001b[1;35mget\u001b[0m\n    raise self._value\n",
      "  File \u001b[1;32m\"/usr/lib/python3.6/multiprocessing/pool.py\"\u001b[0m, line \u001b[1;32m119\u001b[0m, in \u001b[1;35mworker\u001b[0m\n    result = (True, func(*args, **kwds))\n",
      "  File \u001b[1;32m\"/home/nuclearvodka/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\"\u001b[0m, line \u001b[1;32m626\u001b[0m, in \u001b[1;35mnext_sample\u001b[0m\n    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \u001b[1;32m\"<ipython-input-41-7fe434a294e9>\"\u001b[0m, line \u001b[1;32m40\u001b[0m, in \u001b[1;35mcsv_generator\u001b[0m\n    y1 = ast.literal_eval(empty_string)\n",
      "  File \u001b[1;32m\"/usr/lib/python3.6/ast.py\"\u001b[0m, line \u001b[1;32m48\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/lib/python3.6/ast.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, PyCF_ONLY_AST)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ['au_niveau_de', a_l'exterieur_de]\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "run_10_geometric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
