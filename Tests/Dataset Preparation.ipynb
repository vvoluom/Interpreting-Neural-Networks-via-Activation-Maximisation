{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import h5py\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(data,data_in,CATEGORIES):\n",
    "    img = data[data_in].get('filename','')\n",
    "    DATADIR = \"sg_dataset\"\n",
    "    \n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR,category)\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_COLOR)\n",
    "        break\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_object(data,data_in,rel_in):\n",
    "    ob1 = data[data_in].get('relationships',)[rel_in].get('objects','')[0]\n",
    "    ob2 = data[data_in].get('relationships',)[rel_in].get('objects','')[1]\n",
    "    return ob1,ob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate(data,data_in,ob1,ob2):\n",
    "    y1 = data[data_in].get('objects','')[ob1].get('bbox','').get('y','')\n",
    "    x1 = data[data_in].get('objects','')[ob1].get('bbox','').get('x','')\n",
    "    w1 = data[data_in].get('objects','')[ob1].get('bbox','').get('w','')\n",
    "    h1 = data[data_in].get('objects','')[ob1].get('bbox','').get('h','')\n",
    "\n",
    "    y2 = data[data_in].get('objects','')[ob2].get('bbox','').get('y','')\n",
    "    x2 = data[data_in].get('objects','')[ob2].get('bbox','').get('x','')\n",
    "    w2 = data[data_in].get('objects','')[ob2].get('bbox','').get('w','')\n",
    "    h2 = data[data_in].get('objects','')[ob2].get('bbox','').get('h','')\n",
    "    return x1,y1,w1,h1,x2,y2,w2,h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnionBox(x1,x2,y1,y2,h1,h2,w1,w2):\n",
    "    ub_x = 0\n",
    "    ub_y = 0\n",
    "    ub_w = 0\n",
    "    ub_h = 0\n",
    "\n",
    "    if x1 > x2:\n",
    "        ub_x = x2\n",
    "    else:\n",
    "        ub_x = x1\n",
    "\n",
    "    if y1 > y2:\n",
    "        ub_y = y2\n",
    "    else:\n",
    "        ub_y = y1\n",
    "\n",
    "    if x1+w1 > x2+w2:\n",
    "        ub_w = x1+w1-ub_x\n",
    "    else:\n",
    "        ub_w = x2+w2-ub_x\n",
    "\n",
    "    if y1+h1 > y2+h2:\n",
    "        ub_h = y1+h1-ub_y\n",
    "    else:\n",
    "        ub_h = y2+h2-ub_y\n",
    "        \n",
    "    return ub_x,ub_y,ub_w,ub_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img_arr,ub_y,ub_x,ub_w,ub_h):\n",
    "    #crop the image with the union box and return it\n",
    "    #Use this for Union_WB_B method to black out the exterior\n",
    "    crop_img = img_arr[int(ub_y):int(ub_y+ub_h), int(ub_x):int(ub_x+ub_w)].copy()\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rel(rel):\n",
    "    #predicats = ['above','behind','beneath','left of','right of',\n",
    "    #             'below','has','hold','in','inside','in front of','near',\n",
    "    #             'next to','on','on the left of','on the right of',\n",
    "    #             'under','wear','at','has on','adjacent to','is behind the','is to left of',\n",
    "    #             'is right of the','']\n",
    "    \n",
    "    spatial  = ['about','above','across','against','along','alongside','around'\n",
    "                ,'at','atop','behind','beneath','below','beside','beyond'\n",
    "                ,'close to','far from','front','inside','opposite','outside'\n",
    "                ,'near','next','top','over','past','through','toward','within'\n",
    "                'left','right','under']\n",
    "    special = ['on','in','by','up']\n",
    "    rel1 = rel\n",
    "    #print(rel)\n",
    "    for i in spatial:\n",
    "        if rel in special:\n",
    "            return rel\n",
    "        elif rel.find(i) != -1:\n",
    "            #print(rel1)\n",
    "            #print(i)\n",
    "            rel = i\n",
    "            return rel\n",
    "        #elif i.find(rel) != -1:\n",
    "            #rel = i\n",
    "            #return rel\n",
    "            #print(\"FAILURE \",rel1)\n",
    "            \n",
    "        #    print (\"Found\",rel)\n",
    "    #rel = None\n",
    "    #if rel not in spatial:\n",
    "    #    rel = None\n",
    "    rel = None\n",
    "    return rel\n",
    "\n",
    "#Objects aren't needed only saving relationships not training object classifier\n",
    "def check_obj(obj1,obj2):\n",
    "    objs = ['airplane','bag','ball','basket','bear','bed','bench',\n",
    "            'bike','boat','bottle','bowl','box','building','bus',\n",
    "            'bush','cabinet','camera','can','car','cart','cat','chair',\n",
    "            'clock','coat','computer','cone','counter','cup','desk','dog',\n",
    "            'elephant','engine','face','faucet','giraffe','glasses','grass',\n",
    "            'hand','hat','helmet','horse','hydrant','jacket','jeans','keyboard',\n",
    "            'kite','lamp','laptop','luggage','monitor','motorcycle','mountain',\n",
    "            'mouse','oven','pants','paper','person','phone','pillow','pizza',\n",
    "            'plane','plant','plate','post','pot','ramp','refrigerator','road',\n",
    "            'roof','sand','shelf','shirt','shoe','shoes','shorts','sink','skateboard',\n",
    "            'skis','sky','snowboard','sofa','stove','street',\n",
    "            'suitcase','sunglasses','surfboard','table','tie',\n",
    "            'tower','traffic light','train','trash can','tree',\n",
    "            'trees','truck','umbrella','van','vase','watch','wheel']\n",
    "    \n",
    "    #if obj1 not in objs:\n",
    "    #    obj1 = None\n",
    "    \n",
    "    #if obj2 not in objs:\n",
    "    #    obj2 = None\n",
    "    \n",
    "    return obj1,obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(data,data_in,rel_in,crop_img,new_dir):\n",
    "    \n",
    "    ob1_name = data[data_in].get('relationships',)[rel_in].get('text','')[0]\n",
    "    rel = data[data_in].get('relationships',)[rel_in].get('text','')[1]\n",
    "    ob2_name = data[data_in].get('relationships',)[rel_in].get('text','')[2]\n",
    "    rel = check_rel(rel)\n",
    "    #ob1_name,ob2_name = check_obj(ob1_name,ob2_name)\n",
    "    \n",
    "    if rel != None:\n",
    "        image_name = data[data_in].get('filename',)[:-4]+\"_\"+ob1_name+\"_\"+rel+\"_\"+ob2_name+\"0\"+\".jpg\"\n",
    "        name = rel\n",
    "        #Name directory after the label\n",
    "        #name = rel\n",
    "        dirName = new_dir+name\n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir(dirName)\n",
    "            #print(\"Directory \" , dirName ,  \" Created \") \n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        filename = dirName+\"/\"+image_name.replace(\" \", \"\")\n",
    "        exists = False\n",
    "        i = int(filename[len(filename)-5:-4])\n",
    "        while exists != True:\n",
    "            if (os.path.isfile(filename) != True):\n",
    "                cv2.imwrite(filename,crop_img)\n",
    "                exists = True\n",
    "            else:\n",
    "                i += 1\n",
    "                filename = filename[:-5]+str(i)+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Union_WB_B(img_array,x1,y1,h1,w1,x2,y2,h2,w2):\n",
    "    \n",
    "    img_array[0:img_array.shape[0] , 0:img_array.shape[1]] = (0,0,0)\n",
    "    img_array[int(y1):int(y1+h1), int(x1):int(x1+w1)] = (0,255,0)\n",
    "    img_array[int(y2):int(y2+h2), int(x2):int(x2+w2)] = (255,0,0)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "def Union_WB(img_array,x1,y1,h1,w1,x2,y2,h2,w2):\n",
    "    obj1 = img_array[int(y1):int(y1+h1), int(x1):int(x1+w1),:].copy()\n",
    "    obj2 = img_array[int(y2):int(y2+h2), int(x2):int(x2+w2),:].copy()\n",
    "\n",
    "    #temp_array = img_array.copy()\n",
    "    temp_array = np.zeros(img_array.shape, np.uint8)\n",
    "    #temp_array[int(y1):int(y1+h1), int(x1):int(x1+w1),:] = obj1\n",
    "    #temp_array[:,:,:] = img_array[0:img_array.shape[0] , 0:img_array.shape[1],:]\n",
    "    temp_array[int(y1):int(y1+h1), int(x1):int(x1+w1),:] = img_array[int(y1):int(y1+h1), int(x1):int(x1+w1),:].copy()\n",
    "    temp_array[int(y2):int(y2+h2), int(x2):int(x2+w2),:] = img_array[int(y2):int(y2+h2), int(x2):int(x2+w2),:].copy()\n",
    "\n",
    "    return temp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_images(method,data,CATEGORIES):\n",
    "    #Extracting the required data\n",
    "    for i in range(len(data)):\n",
    "        img_array = get_image(data,i,CATEGORIES)\n",
    "        for j in range(len(data[i].get('relationships',))):\n",
    "            try:\n",
    "                obj1 , obj2 = get_object(data,i,j)\n",
    "                x1,y1,w1,h1,x2,y2,w2,h2 = get_coordinate(data,i,obj1,obj2)\n",
    "                ub_x,ub_y,ub_w,ub_h = UnionBox(x1,x2,y1,y2,h1,h2,w1,w2)\n",
    "                \n",
    "                if method is \"Union_WB_B\":\n",
    "                    img_array1 = Union_WB_B(img_array.copy(),x1,y1,h1,w1,x2,y2,h2,w2)\n",
    "                    crop_img = crop_image(img_array1,ub_y,ub_x,ub_w,ub_h)\n",
    "                    crop_img = cv2.resize(crop_img, (224, 224))\n",
    "                    write_to_file(data,i,j,crop_img,\"Union_WB_B/\")\n",
    "                elif method is \"Union\":\n",
    "                    crop_img = crop_image(img_array,ub_y,ub_x,ub_w,ub_h)\n",
    "                    crop_img = cv2.resize(crop_img, (224, 224))\n",
    "                    write_to_file(data,i,j,crop_img,\"Union/\")\n",
    "                elif method is \"Union_WB\":\n",
    "                    img_array1 = Union_WB(img_array.copy(),x1,y1,h1,w1,x2,y2,h2,w2)\n",
    "                    crop_img = crop_image(img_array1,ub_y,ub_x,ub_w,ub_h)\n",
    "                    crop_img = cv2.resize(crop_img, (224, 224))\n",
    "                    write_to_file(data,i,j,crop_img,\"Union_WB/\") \n",
    "                else:\n",
    "                    print(\"ERROR\")\n",
    "                    break\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sg_dataset/sg_train_annotations.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "execute_images(\"Union\",data,[\"sg_train_images\"])\n",
    "execute_images(\"Union_WB\",data,[\"sg_train_images\"])\n",
    "execute_images(\"Union_WB_B\",data,[\"sg_train_images\"])\n",
    "\n",
    "with open('sg_dataset/sg_test_annotations.json') as f1:\n",
    "    data1 = json.load(f1)\n",
    "\n",
    "execute_images(\"Union\",data1,[\"sg_test_images\"])\n",
    "execute_images(\"Union_WB\",data1,[\"sg_test_images\"])\n",
    "execute_images(\"Union_WB_B\",data1,[\"sg_test_images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def write_cvs(dataset):\n",
    "    # grab all image paths and create a training and testing split\n",
    "    imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "    random.shuffle(imagePaths)\n",
    "    i = int(len(imagePaths) * 0.20)\n",
    "    j = int(len(imagePaths) * 0.60)\n",
    "    \n",
    "    trainPaths = imagePaths[:j]\n",
    "    testPaths = imagePaths[j:j+i]\n",
    "    validPaths = imagePaths[j+i:]\n",
    "    \n",
    "    csv_path_training = dataset+\"_training.csv\"\n",
    "    csv_path_testing = dataset+\"_testing.csv\"\n",
    "    csv_path_validation = dataset+\"_validation.csv\"\n",
    "\n",
    "    #define the datasets\n",
    "    datasets = [\n",
    "        (\"training\", trainPaths, csv_path_training),\n",
    "        (\"testing\", testPaths, csv_path_testing),\n",
    "        (\"validation\", validPaths, csv_path_validation)\n",
    "    ]\n",
    "    \n",
    "    # loop over the data splits\n",
    "    for (dType, imagePaths, outputPath) in datasets:\n",
    "        # open the output CSV file for writing\n",
    "        print(\"[INFO] building '{}' split...\".format(dType))\n",
    "        f = open(outputPath, \"w\")\n",
    "\n",
    "        # loop over all input images\n",
    "        for imagePath in imagePaths:\n",
    "            try:\n",
    "                # load the input image and resize it to 64x64 pixels\n",
    "                image = cv2.imread(imagePath)\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "\n",
    "                # create a flattened list of pixel values\n",
    "                image = [str(x) for x in image.flatten()]\n",
    "\n",
    "                # extract the class label from the file path and write the\n",
    "                # label along pixels list to disk\n",
    "                label = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
    "                label = label[0]+','+label[1]\n",
    "                f.write(\"{},{}\\n\".format(label, \",\".join(image)))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # close the output CSV file\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cvs(\"Union\")\n",
    "write_cvs(\"Union_WB\")\n",
    "write_cvs(\"Union_WB_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing clothes set\n",
    "write_cvs(\"datasetClothes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sg_dataset/sg_test_annotations.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vrd = []\n",
    "for i in range(len(data)):\n",
    "    filename = data[i].get('filename','')\n",
    "    for j in range(len(data[i].get('relationships',''))):\n",
    "        \n",
    "        relationship = data[i].get('relationships','')[j].get('text','')[1]\n",
    "        relationship = check_rel(relationship)\n",
    "        \n",
    "        if relationship != None:    \n",
    "            \n",
    "            ob1,ob2 = get_object(data,i,j)\n",
    "            object_name_1 = data[i].get('relationships','')[j].get('text','')[0]\n",
    "            object_name_2 = data[i].get('relationships','')[j].get('text','')[2]\n",
    "            x1,y1,w1,h1,x2,y2,w2,h2 = get_coordinate(data,i,ob1,ob2)\n",
    "            input_vrd = [filename,object_name_1,object_name_2,[x1,y1,w1,h1],[x2,y2,w2,h2],[relationship]]\n",
    "            new_vrd.append(input_vrd)\n",
    "        \n",
    "        #print(object1+\" \"+relationship+\" \"+object2)\n",
    "        #rel = data[data_in].get('relationships',)[rel_in].get('text','')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_appeneded = []\n",
    "preposition = []\n",
    "old_vrd = new_vrd\n",
    "lenght_of_list = len(new_vrd)\n",
    "j = 0 \n",
    "i = 0\n",
    "while j < lenght_of_list:\n",
    "    #print(i , j , lenght_of_list)\n",
    "    if i > 5:\n",
    "        i = j-5\n",
    "    else:\n",
    "        i = j\n",
    "    while i < lenght_of_list:\n",
    "        #print(new_vrd[j][0] ,new_vrd[i][0])\n",
    "        if (i != j) and (new_vrd[j][0] == new_vrd[i][0]) and (new_vrd[j][1] == new_vrd[i][1]) and (new_vrd[j][2] == new_vrd[i][2]) and (new_vrd[j][3] == new_vrd[i][3]) and (new_vrd[j][4] == new_vrd[i][4]):\n",
    "            set1 = set(new_vrd[j][5])\n",
    "            set2 = set(new_vrd[i][5])\n",
    "            print(set1 , set2 , i , j)\n",
    "            new_appeneded = []\n",
    "            preposition = []\n",
    "            if set1 != set2 and ((not (set1.issubset(set2))) and (not (set2.issubset(set1)))):\n",
    "                for k in range(len(new_vrd[j][5])):\n",
    "                    preposition.append(new_vrd[j][5][k])\n",
    "                for k1 in range(len(new_vrd[i][5])):\n",
    "                    preposition.append(new_vrd[i][5][k1])\n",
    "                    \n",
    "                new_appeneded = [new_vrd[j][0],new_vrd[j][1],new_vrd[j][2],new_vrd[j][3],new_vrd[j][4],list(set(preposition))]\n",
    "                new_vrd.remove(new_vrd[i])\n",
    "                print(new_appeneded)\n",
    "                new_vrd.insert(i,new_appeneded)\n",
    "                #lenght_of_list -= 1\n",
    "                j -= 7\n",
    "                i -= 7\n",
    "            elif (set1 != set2) and (set1.issubset(set2)):\n",
    "                new_vrd.remove(new_vrd[j])\n",
    "                lenght_of_list -= 1\n",
    "                j -= 7\n",
    "                i -= 7\n",
    "            elif (set1 == set2) or (set2.issubset(set1)):\n",
    "                #print(\"GETTING REMOVED 2\",new_vrd[i])\n",
    "                #print(\"GETTING REMOVED 21\",new_vrd[j])\n",
    "                new_vrd.remove(new_vrd[i])\n",
    "                lenght_of_list -= 1\n",
    "                j -= 7\n",
    "                i -= 7\n",
    "                #i = j-1\n",
    "                #i -= 1\n",
    "\n",
    "        i += 1\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(new_vrd)):\n",
    "    for y in range(len(new_vrd)):\n",
    "        if (new_vrd[x][0] == new_vrd[y][0]) and (new_vrd[x][1] == new_vrd[y][1]) and (new_vrd[x][2] == new_vrd[y][2]) and (x != y) and (new_vrd[x][3] == new_vrd[y][3]) and (new_vrd[x][4] == new_vrd[y][4]):\n",
    "            print(new_vrd[x],x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"Multi_label_predictions.csv\",\"a\",newline=\"\") as f: \n",
    "    cw = csv.writer(f)\n",
    "    cw.writerows(r+[\"\"] for r in new_vrd)\n",
    "f.close()\n",
    "    \n",
    "#print(set(new_vrd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4378\n",
      "78349\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "with open('Multi_label_predictions.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    your_list = list(reader)\n",
    "\n",
    "all_labels = []\n",
    "number_multi_labels = 0\n",
    "singel_labels = 0 \n",
    "combinations = []\n",
    "for i in range(len(your_list)):\n",
    "    x = your_list[i][5]\n",
    "    x = ast.literal_eval(x)\n",
    "    x = [n.strip() for n in x]\n",
    "    if len(x) > 1:\n",
    "        number_multi_labels += 1\n",
    "        combinations.append(x)\n",
    "        for j in x:\n",
    "            singel_labels += 1\n",
    "            all_labels.append(j)\n",
    "    else:\n",
    "        #print(x[0])\n",
    "        #print(x)\n",
    "        singel_labels += 1\n",
    "        all_labels.append(x[0])\n",
    "\n",
    "print(number_multi_labels)\n",
    "print(singel_labels)\n",
    "dictionary_labels = Counter(all_labels)\n",
    "#dictionary_combinations = Counter(combinations)\n",
    "        #print(your_list[i][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_counter = Counter(tuple(item) for item in combinations)\n",
    "#print(new_counter)\n",
    "for k, v in new_counter.items():\n",
    "    print(k,v)\n",
    "    #print(k , v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the counters of the labels\n",
    "train_labels = []\n",
    "test_labels =[]\n",
    "valid_labels = []\n",
    "#Store information of image\n",
    "train_info = []\n",
    "test_info = []\n",
    "valid_info = []\n",
    "\n",
    "#This should only iterate for multi labels first then\n",
    "#It will go through \n",
    "all_labels = []\n",
    "multi_labels_count = 0\n",
    "single_labels_count = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "count5 = 0\n",
    "count6 = 0\n",
    "count7 = 0\n",
    "for i in range(len(your_list)):\n",
    "    x = your_list[i][5]\n",
    "    x = ast.literal_eval(x)\n",
    "    x = [n.strip() for n in x]\n",
    "    \n",
    "    #print(Counter(test_labels).get(x[0]))\n",
    "    #This is for multi labels\n",
    "    if len(x) > 1:\n",
    "        multi_labels_count += 1\n",
    "        if (Counter(test_labels).get(x[0]) == None):\n",
    "            count1 += 1\n",
    "            test_info.append(your_list[i])\n",
    "            for j in x:\n",
    "                test_labels.append(j)\n",
    "        elif (Counter(valid_labels).get(x[0]) == None):\n",
    "            count2 += 1\n",
    "            valid_info.append(your_list[i])\n",
    "            for j in x:\n",
    "                valid_labels.append(j)\n",
    "        elif (Counter(train_labels).get(x[0]) == None):\n",
    "            count3 += 1\n",
    "            train_info.append(your_list[i])\n",
    "            for j in x:\n",
    "                train_labels.append(j)\n",
    "        else:\n",
    "            if Counter(test_labels).get(x[0]) < Counter(valid_labels).get(x[0]):\n",
    "                count4 += 1\n",
    "                test_info.append(your_list[i])\n",
    "                for j in x:\n",
    "                    test_labels.append(j)\n",
    "            elif Counter(test_labels).get(x[0]) > Counter(valid_labels).get(x[0]):\n",
    "                count5 += 1\n",
    "                valid_info.append(your_list[i])\n",
    "                for j in x:\n",
    "                    valid_labels.append(j)\n",
    "            elif Counter(train_labels).get(x[0]) <= ((Counter(valid_labels).get(x[0]) + Counter(train_labels).get(x[0]) + Counter(test_labels).get(x[0])) * 0.60):\n",
    "                count6 += 1\n",
    "                train_info.append(your_list[i])\n",
    "                for j in x:\n",
    "                    train_labels.append(j)\n",
    "            elif Counter(test_labels).get(x[0]) == Counter(valid_labels).get(x[0]):\n",
    "                count4 += 1\n",
    "                test_info.append(your_list[i])\n",
    "                for j in x:\n",
    "                    test_labels.append(j)\n",
    "            else:\n",
    "                print(Counter(test_labels).get(x[0]))\n",
    "                print(Counter(valid_labels).get(x[0]))\n",
    "                print(Counter(train_labels).get(x[0]))\n",
    "                count7 += 1\n",
    "    else:\n",
    "        single_labels_count += 1\n",
    "        if (Counter(test_labels).get(x[0]) == None):\n",
    "            count1 += 1\n",
    "            test_info.append(your_list[i])\n",
    "            test_labels.append(x[0])\n",
    "            \n",
    "        elif (Counter(valid_labels).get(x[0]) == None):\n",
    "            count2 += 1\n",
    "            valid_info.append(your_list[i])\n",
    "            valid_labels.append(x[0])\n",
    "        elif (Counter(train_labels).get(x[0]) == None):\n",
    "            count3 += 1\n",
    "            train_info.append(your_list[i])\n",
    "            train_labels.append(x[0])\n",
    "        else:\n",
    "            if Counter(test_labels).get(x[0]) < Counter(valid_labels).get(x[0]):\n",
    "                count4 += 1\n",
    "                test_info.append(your_list[i])\n",
    "                test_labels.append(x[0])\n",
    "            elif Counter(test_labels).get(x[0]) > Counter(valid_labels).get(x[0]):\n",
    "                count5 += 1\n",
    "                valid_info.append(your_list[i])\n",
    "                valid_labels.append(x[0])\n",
    "            elif Counter(train_labels).get(x[0]) <= ((Counter(valid_labels).get(x[0]) + Counter(train_labels).get(x[0]) + Counter(test_labels).get(x[0])) * 0.60):\n",
    "                count6 += 1\n",
    "                train_info.append(your_list[i])\n",
    "                train_labels.append(x[0])\n",
    "            elif Counter(test_labels).get(x[0]) == Counter(valid_labels).get(x[0]):\n",
    "                count4 += 1\n",
    "                test_info.append(your_list[i])\n",
    "                test_labels.append(x[0])\n",
    "            else:\n",
    "                print(Counter(test_labels).get(x[0]))\n",
    "                print(Counter(valid_labels).get(x[0]))\n",
    "                print(Counter(train_labels).get(x[0]))\n",
    "                count7 += 1\n",
    "            \n",
    "            \n",
    "    #This is for single labels.\n",
    "    #else:\n",
    "        #print(x[0])\n",
    "        #print(x)\n",
    "    #    singel_labels += 1\n",
    "    #    all_labels.append(x[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4378\n",
      "68952\n",
      "43992\n",
      "14652\n",
      "14686\n",
      "Train Labels Counter\n",
      "Counter({'on': 12763, 'above': 5206, 'next': 4544, 'behind': 4523, 'front': 3179, 'under': 3066, 'near': 2686, 'in': 2221, 'below': 1811, 'at': 1597, 'beside': 1435, 'over': 1291, 'by': 792, 'right': 731, 'top': 592, 'inside': 145, 'against': 131, 'around': 88, 'across': 55, 'outside': 49, 'along': 28, 'beyond': 13, 'far from': 11, 'toward': 8, 'past': 7, 'close to': 6, 'through': 5, 'opposite': 4, 'about': 4})\n",
      "Test Labels Counter\n",
      "Counter({'on': 4254, 'above': 1737, 'next': 1515, 'behind': 1508, 'front': 1060, 'under': 1022, 'near': 897, 'in': 741, 'below': 604, 'at': 533, 'beside': 479, 'over': 432, 'by': 264, 'right': 244, 'top': 198, 'inside': 49, 'against': 44, 'around': 31, 'across': 19, 'outside': 17, 'along': 10, 'beyond': 5, 'far from': 4, 'through': 3, 'past': 3, 'toward': 3, 'about': 3, 'close to': 2, 'opposite': 2})\n",
      "Valid Labels Counter\n",
      "Counter({'on': 4254, 'above': 1736, 'next': 1515, 'behind': 1508, 'front': 1060, 'under': 1022, 'near': 897, 'in': 741, 'below': 604, 'at': 533, 'beside': 479, 'over': 432, 'by': 264, 'right': 244, 'top': 198, 'inside': 49, 'against': 44, 'around': 30, 'across': 19, 'outside': 16, 'along': 9, 'beyond': 4, 'far from': 4, 'through': 3, 'toward': 3, 'close to': 2, 'past': 2, 'opposite': 2, 'about': 1})\n",
      "29\n",
      "29\n",
      "22\n",
      "14623\n",
      "14657\n",
      "43970\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(multi_labels_count)\n",
    "print(single_labels_count)\n",
    "\n",
    "print(len(train_info))\n",
    "print(len(test_info))\n",
    "print(len(valid_info))\n",
    "\n",
    "print(\"Train Labels Counter\")\n",
    "print(Counter(train_labels))\n",
    "print(\"Test Labels Counter\")\n",
    "print(Counter(test_labels))\n",
    "print(\"Valid Labels Counter\")\n",
    "print(Counter(valid_labels))\n",
    "\n",
    "print(count1)\n",
    "print(count2)\n",
    "print(count3)\n",
    "print(count4)\n",
    "print(count5)\n",
    "print(count6)\n",
    "print(count7)\n",
    "#print(range(Counter(all_labels).get('on')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"Training_Multi_label_predictions.csv\",\"w\",newline=\"\") as f: \n",
    "    cw = csv.writer(f)\n",
    "    cw.writerows(r+[\"\"] for r in train_info)\n",
    "f.close()\n",
    "\n",
    "\n",
    "with open(\"Testing_Multi_label_predictions.csv\",\"w\",newline=\"\") as f: \n",
    "    cw = csv.writer(f)\n",
    "    cw.writerows(r+[\"\"] for r in test_info)\n",
    "f.close()\n",
    "\n",
    "\n",
    "with open(\"Validation_Multi_label_predictions.csv\",\"w\",newline=\"\") as f: \n",
    "    cw = csv.writer(f)\n",
    "    cw.writerows(r+[\"\"] for r in valid_info)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
