{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import h5py\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(data,data_in,CATEGORIES):\n",
    "    img = data[data_in].get('filename','')\n",
    "    DATADIR = \"sg_dataset\"\n",
    "    \n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR,category)\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_COLOR)\n",
    "        break\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_object(data,data_in,rel_in):\n",
    "    ob1 = data[data_in].get('relationships',)[rel_in].get('objects','')[0]\n",
    "    ob2 = data[data_in].get('relationships',)[rel_in].get('objects','')[1]\n",
    "    return ob1,ob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate(data,data_in,ob1,ob2):\n",
    "    y1 = data[data_in].get('objects','')[ob1].get('bbox','').get('y','')\n",
    "    x1 = data[data_in].get('objects','')[ob1].get('bbox','').get('x','')\n",
    "    w1 = data[data_in].get('objects','')[ob1].get('bbox','').get('w','')\n",
    "    h1 = data[data_in].get('objects','')[ob1].get('bbox','').get('h','')\n",
    "\n",
    "    y2 = data[data_in].get('objects','')[ob2].get('bbox','').get('y','')\n",
    "    x2 = data[data_in].get('objects','')[ob2].get('bbox','').get('x','')\n",
    "    w2 = data[data_in].get('objects','')[ob2].get('bbox','').get('w','')\n",
    "    h2 = data[data_in].get('objects','')[ob2].get('bbox','').get('h','')\n",
    "    return x1,y1,w1,h1,x2,y2,w2,h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnionBox(x1,x2,y1,y2,h1,h2,w1,w2):\n",
    "    ub_x = 0\n",
    "    ub_y = 0\n",
    "    ub_w = 0\n",
    "    ub_h = 0\n",
    "\n",
    "    if x1 > x2:\n",
    "        ub_x = x2\n",
    "    else:\n",
    "        ub_x = x1\n",
    "\n",
    "    if y1 > y2:\n",
    "        ub_y = y2\n",
    "    else:\n",
    "        ub_y = y1\n",
    "\n",
    "    if x1+w1 > x2+w2:\n",
    "        ub_w = x1+w1-ub_x\n",
    "    else:\n",
    "        ub_w = x2+w2-ub_x\n",
    "\n",
    "    if y1+h1 > y2+h2:\n",
    "        ub_h = y1+h1-ub_y\n",
    "    else:\n",
    "        ub_h = y2+h2-ub_y\n",
    "        \n",
    "    return ub_x,ub_y,ub_w,ub_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img_arr,ub_y,ub_x,ub_w,ub_h):\n",
    "    #crop the image with the union box and return it\n",
    "    #Use this for Union_WB_B method to black out the exterior\n",
    "    crop_img = img_arr[int(ub_y):int(ub_y+ub_h), int(ub_x):int(ub_x+ub_w)].copy()\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rel(rel):\n",
    "    #predicats = ['above','behind','beneath','left of','right of',\n",
    "    #             'below','has','hold','in','inside','in front of','near',\n",
    "    #             'next to','on','on the left of','on the right of',\n",
    "    #             'under','wear','at','has on','adjacent to','is behind the','is to left of',\n",
    "    #             'is right of the','']\n",
    "    \n",
    "    spatial  = ['above','behind','beneath','below','has',\n",
    "                'in','front','near','next','top',\n",
    "                 'on','left','right','under']\n",
    "    rel1 = rel\n",
    "    for i in spatial:\n",
    "        if rel.find(i) == 0:\n",
    "            #print(rel1)\n",
    "            #print(i)\n",
    "            rel = i\n",
    "            return rel\n",
    "            #print(\"FAILURE \",rel1)\n",
    "            \n",
    "        #    print (\"Found\",rel)\n",
    "    #rel = None\n",
    "    #if rel not in spatial:\n",
    "    #    rel = None\n",
    "    rel = None\n",
    "    return rel\n",
    "\n",
    "#Objects aren't needed only saving relationships not training object classifier\n",
    "def check_obj(obj1,obj2):\n",
    "    objs = ['airplane','bag','ball','basket','bear','bed','bench',\n",
    "            'bike','boat','bottle','bowl','box','building','bus',\n",
    "            'bush','cabinet','camera','can','car','cart','cat','chair',\n",
    "            'clock','coat','computer','cone','counter','cup','desk','dog',\n",
    "            'elephant','engine','face','faucet','giraffe','glasses','grass',\n",
    "            'hand','hat','helmet','horse','hydrant','jacket','jeans','keyboard',\n",
    "            'kite','lamp','laptop','luggage','monitor','motorcycle','mountain',\n",
    "            'mouse','oven','pants','paper','person','phone','pillow','pizza',\n",
    "            'plane','plant','plate','post','pot','ramp','refrigerator','road',\n",
    "            'roof','sand','shelf','shirt','shoe','shoes','shorts','sink','skateboard',\n",
    "            'skis','sky','snowboard','sofa','stove','street',\n",
    "            'suitcase','sunglasses','surfboard','table','tie',\n",
    "            'tower','traffic light','train','trash can','tree',\n",
    "            'trees','truck','umbrella','van','vase','watch','wheel']\n",
    "    \n",
    "    #if obj1 not in objs:\n",
    "    #    obj1 = None\n",
    "    \n",
    "    #if obj2 not in objs:\n",
    "    #    obj2 = None\n",
    "    \n",
    "    return obj1,obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(data,data_in,rel_in,crop_img,new_dir):\n",
    "    \n",
    "    ob1_name = data[data_in].get('relationships',)[rel_in].get('text','')[0]\n",
    "    rel = data[data_in].get('relationships',)[rel_in].get('text','')[1]\n",
    "    ob2_name = data[data_in].get('relationships',)[rel_in].get('text','')[2]\n",
    "    rel = check_rel(rel)\n",
    "    #ob1_name,ob2_name = check_obj(ob1_name,ob2_name)\n",
    "    \n",
    "    if rel != None:\n",
    "        image_name = data[data_in].get('filename',)[:-4]+\"_\"+ob1_name+\"_\"+rel+\"_\"+ob2_name+\"0\"+\".jpg\"\n",
    "        name = rel\n",
    "        #Name directory after the label\n",
    "        #name = rel\n",
    "        dirName = new_dir+name\n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir(dirName)\n",
    "            #print(\"Directory \" , dirName ,  \" Created \") \n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        filename = dirName+\"/\"+image_name.replace(\" \", \"\")\n",
    "        exists = False\n",
    "        i = int(filename[len(filename)-5:-4])\n",
    "        while exists != True:\n",
    "            if (os.path.isfile(filename) != True):\n",
    "                cv2.imwrite(filename,crop_img)\n",
    "                exists = True\n",
    "            else:\n",
    "                i += 1\n",
    "                filename = filename[:-5]+str(i)+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Union_WB_B(img_array,x1,y1,h1,w1,x2,y2,h2,w2):\n",
    "    \n",
    "    img_array[0:img_array.shape[0] , 0:img_array.shape[1]] = (0,0,0)\n",
    "    img_array[int(y1):int(y1+h1), int(x1):int(x1+w1)] = (0,255,0)\n",
    "    img_array[int(y2):int(y2+h2), int(x2):int(x2+w2)] = (255,0,0)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "def Union_WB(img_array,x1,y1,h1,w1,x2,y2,h2,w2):\n",
    "    obj1 = img_array[int(y1):int(y1+h1), int(x1):int(x1+w1),:].copy()\n",
    "    obj2 = img_array[int(y2):int(y2+h2), int(x2):int(x2+w2),:].copy()\n",
    "\n",
    "    #temp_array = img_array.copy()\n",
    "    temp_array = np.zeros(img_array.shape, np.uint8)\n",
    "    #temp_array[int(y1):int(y1+h1), int(x1):int(x1+w1),:] = obj1\n",
    "    #temp_array[:,:,:] = img_array[0:img_array.shape[0] , 0:img_array.shape[1],:]\n",
    "    temp_array[int(y1):int(y1+h1), int(x1):int(x1+w1),:] = img_array[int(y1):int(y1+h1), int(x1):int(x1+w1),:].copy()\n",
    "    temp_array[int(y2):int(y2+h2), int(x2):int(x2+w2),:] = img_array[int(y2):int(y2+h2), int(x2):int(x2+w2),:].copy()\n",
    "\n",
    "    return temp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_images(method,data,CATEGORIES):\n",
    "    #Extracting the required data\n",
    "    for i in range(len(data)):\n",
    "        img_array = get_image(data,i,CATEGORIES)\n",
    "        for j in range(len(data[i].get('relationships',))):\n",
    "            try:\n",
    "                obj1 , obj2 = get_object(data,i,j)\n",
    "                x1,y1,w1,h1,x2,y2,w2,h2 = get_coordinate(data,i,obj1,obj2)\n",
    "                ub_x,ub_y,ub_w,ub_h = UnionBox(x1,x2,y1,y2,h1,h2,w1,w2)\n",
    "                \n",
    "                if method is \"Union_WB_B\":\n",
    "                    img_array1 = Union_WB_B(img_array.copy(),x1,y1,h1,w1,x2,y2,h2,w2)\n",
    "                    crop_img = crop_image(img_array1,ub_y,ub_x,ub_w,ub_h)\n",
    "                    crop_img = cv2.resize(crop_img, (224, 224))\n",
    "                    write_to_file(data,i,j,crop_img,\"Union_WB_B/\")\n",
    "                elif method is \"Union\":\n",
    "                    crop_img = crop_image(img_array,ub_y,ub_x,ub_w,ub_h)\n",
    "                    crop_img = cv2.resize(crop_img, (224, 224))\n",
    "                    write_to_file(data,i,j,crop_img,\"Union/\")\n",
    "                elif method is \"Union_WB\":\n",
    "                    img_array1 = Union_WB(img_array.copy(),x1,y1,h1,w1,x2,y2,h2,w2)\n",
    "                    crop_img = crop_image(img_array1,ub_y,ub_x,ub_w,ub_h)\n",
    "                    crop_img = cv2.resize(crop_img, (224, 224))\n",
    "                    write_to_file(data,i,j,crop_img,\"Union_WB/\") \n",
    "                else:\n",
    "                    print(\"ERROR\")\n",
    "                    break\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sg_dataset/sg_train_annotations.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "execute_images(\"Union\",data,[\"sg_train_images\"])\n",
    "execute_images(\"Union_WB\",data,[\"sg_train_images\"])\n",
    "execute_images(\"Union_WB_B\",data,[\"sg_train_images\"])\n",
    "\n",
    "with open('sg_dataset/sg_test_annotations.json') as f1:\n",
    "    data1 = json.load(f1)\n",
    "\n",
    "execute_images(\"Union\",data1,[\"sg_test_images\"])\n",
    "execute_images(\"Union_WB\",data1,[\"sg_test_images\"])\n",
    "execute_images(\"Union_WB_B\",data1,[\"sg_test_images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def write_cvs(dataset):\n",
    "    # grab all image paths and create a training and testing split\n",
    "    imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "    random.shuffle(imagePaths)\n",
    "    i = int(len(imagePaths) * 0.20)\n",
    "    j = int(len(imagePaths) * 0.60)\n",
    "    \n",
    "    trainPaths = imagePaths[:j]\n",
    "    testPaths = imagePaths[j:j+i]\n",
    "    validPaths = imagePaths[j+i:]\n",
    "    \n",
    "    csv_path_training = dataset+\"_training.csv\"\n",
    "    csv_path_testing = dataset+\"_testing.csv\"\n",
    "    csv_path_validation = dataset+\"_validation.csv\"\n",
    "\n",
    "    #define the datasets\n",
    "    datasets = [\n",
    "        (\"training\", trainPaths, csv_path_training),\n",
    "        (\"testing\", testPaths, csv_path_testing),\n",
    "        (\"validation\", validPaths, csv_path_validation)\n",
    "    ]\n",
    "    \n",
    "    # loop over the data splits\n",
    "    for (dType, imagePaths, outputPath) in datasets:\n",
    "        # open the output CSV file for writing\n",
    "        print(\"[INFO] building '{}' split...\".format(dType))\n",
    "        f = open(outputPath, \"w\")\n",
    "\n",
    "        # loop over all input images\n",
    "        for imagePath in imagePaths:\n",
    "            try:\n",
    "                # load the input image and resize it to 64x64 pixels\n",
    "                image = cv2.imread(imagePath)\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "\n",
    "                # create a flattened list of pixel values\n",
    "                image = [str(x) for x in image.flatten()]\n",
    "\n",
    "                # extract the class label from the file path and write the\n",
    "                # label along pixels list to disk\n",
    "                label = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
    "                label = label[0]+','+label[1]\n",
    "                f.write(\"{},{}\\n\".format(label, \",\".join(image)))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # close the output CSV file\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building 'training' split...\n",
      "[INFO] building 'testing' split...\n",
      "[INFO] building 'validation' split...\n",
      "[INFO] building 'training' split...\n",
      "[INFO] building 'testing' split...\n",
      "[INFO] building 'validation' split...\n",
      "[INFO] building 'training' split...\n",
      "[INFO] building 'testing' split...\n",
      "[INFO] building 'validation' split...\n"
     ]
    }
   ],
   "source": [
    "write_cvs(\"Union\")\n",
    "write_cvs(\"Union_WB\")\n",
    "write_cvs(\"Union_WB_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building 'training' split...\n",
      "[INFO] building 'testing' split...\n",
      "[INFO] building 'validation' split...\n"
     ]
    }
   ],
   "source": [
    "#Writing clothes set\n",
    "write_cvs(\"datasetClothes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
