{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import matplotlib\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nottrainable_VGG16(classes,shape,activation_type):\n",
    "    model = VGG16(include_top=False, weights='imagenet',input_shape=(shape,shape,3))\n",
    "    transfer_layer = model.get_layer('block5_pool')\n",
    "    conv_model = Model(inputs=model.input,outputs=transfer_layer.output)\n",
    "    #conv_model.trainable = False\n",
    "    for layer in conv_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    new_model = Sequential()\n",
    "    new_model.add(conv_model)\n",
    "    #Flatten the output of the VGG16 model because its from Conv Layer\t\t\n",
    "    new_model.add(layers.Flatten())\n",
    "    #Add a dense fully connected layer\n",
    "    new_model.add(layers.Dense(1024, activation = 'relu'))\n",
    "    new_model.add(layers.Dropout(0.5))\n",
    "    new_model.add(layers.Dense(classes, activation = activation_type))\n",
    "\n",
    "    # return the constructed network architecture\n",
    "    return new_model\n",
    "\n",
    "def build_trainable_VGG16(classes,shape,activation_type):\n",
    "    model = VGG16(include_top=False, weights='imagenet',input_shape=(shape,shape,3))\n",
    "    transfer_layer = model.get_layer('block5_pool')\n",
    "    conv_model = Model(inputs=model.input,outputs=transfer_layer.output)\n",
    "    #conv_model.trainable = False\n",
    "    #for layer in conv_model.layers:\n",
    "    #    layer.trainable = False\n",
    "    new_model = Sequential()\n",
    "    new_model.add(conv_model)\n",
    "    #Flatten the output of the VGG16 model because its from Conv Layer\t\t\n",
    "    new_model.add(layers.Flatten())\n",
    "    #Add a dense fully connected layer\n",
    "    new_model.add(layers.Dense(1024, activation = 'relu'))\n",
    "    new_model.add(layers.Dropout(0.5))\n",
    "    new_model.add(layers.Dense(classes, activation = activation_type))\n",
    "\n",
    "    # return the constructed network architecture\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_smallvgg(classes,shape,activation_type):\n",
    "    model = Sequential()\n",
    "    inputShape = (shape,shape,3)\n",
    "    chanDim = -1\n",
    "\n",
    "    # CONV => RELU => POOL\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "        input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # sigmoid classifier\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(activation_type))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnionBox(x1,x2,y1,y2,h1,h2,w1,w2):\n",
    "    ub_x = 0\n",
    "    ub_y = 0\n",
    "    ub_w = 0\n",
    "    ub_h = 0\n",
    "\n",
    "    if x1 > x2:\n",
    "        ub_x = x2\n",
    "    else:\n",
    "        ub_x = x1\n",
    "\n",
    "    if y1 > y2:\n",
    "        ub_y = y2\n",
    "    else:\n",
    "        ub_y = y1\n",
    "\n",
    "    if x1+w1 > x2+w2:\n",
    "        ub_w = x1+w1-ub_x\n",
    "    else:\n",
    "        ub_w = x2+w2-ub_x\n",
    "\n",
    "    if y1+h1 > y2+h2:\n",
    "        ub_h = y1+h1-ub_y\n",
    "    else:\n",
    "        ub_h = y2+h2-ub_y\n",
    "        \n",
    "    return ub_x,ub_y,ub_w,ub_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img_arr,ub_y,ub_x,ub_w,ub_h):\n",
    "    #crop the image with the union box and return it\n",
    "    crop_img = img_arr[ub_y:ub_y+ub_h, ub_x:ub_x+ub_w].copy()\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Union_WB_B_Seperate(height,width,x1,y1,h1,w1,x2,y2,h2,w2):\n",
    "    #Create a new array, of 0's with height and width\n",
    "    #Sets to Green\n",
    "    img_array1 = np.zeros((int(height),int(width),3), np.uint8)\n",
    "    img_array1[int(y1):int(y1+h1), int(x1):int(x1+w1)] = (0,255,0)\n",
    "    g = img_array1.copy()\n",
    "    #Split the image only taking the green channel\n",
    "    b1,g1,r1 = cv2.split (g)\n",
    "    img_array2 = np.zeros((int(height),int(width),3), np.uint8)\n",
    "    img_array2[int(y2):int(y2+h2), int(x2):int(x2+w2)] = (255,0,0)\n",
    "    b = img_array2.copy()\n",
    "    #Split blue image take only  blue channel\n",
    "    b2,g2,r2 = cv2.split (b)\n",
    "    #Merge the image\n",
    "    new_img = cv2.merge((b2,g1,r2))\n",
    "    ub_y,ub_x,ub_w,ub_h = UnionBox(x1,x2,y1,y2,h1,h2,w1,w2)\n",
    "    crop_img = crop_image(new_img.copy(),ub_y,ub_x,ub_w,ub_h)\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_image_generator_multilabel(size,inputPath, bs, mlb, mode=\"train\", aug=None):\n",
    "    # open the CSV file for reading\n",
    "    with open(inputPath, 'r') as f1:\n",
    "        reader = csv.reader(f1)\n",
    "        your_list = list(reader)\n",
    "    f1.close()\n",
    "    i = 0\n",
    "    # loop indefinitely\t\n",
    "    while True:\n",
    "        # initialize our batches of images and labels\n",
    "        images = []\n",
    "        labels = []\n",
    "        # keep looping until we reach our batch size\n",
    "        while len(images) < bs and i < (len(your_list)):\n",
    "\n",
    "            if mode == \"eval\" and i == len(your_list):\n",
    "                break\n",
    "            \n",
    "            #Get the labels\n",
    "            x = ast.literal_eval(your_list[i][0])\n",
    "            x = [n.strip() for n in x]\n",
    "            labels.append(x)\n",
    "            \n",
    "            #Get image information and create the image\n",
    "            width = your_list[i][1]\n",
    "            height  = your_list[i][2]\n",
    "    \n",
    "            bb1 = ast.literal_eval(your_list[i][3])\n",
    "            bb1 = [int(n) for n in bb1]\n",
    "            \n",
    "            x1 = abs(bb1[0])\n",
    "            y1 = abs(bb1[1])\n",
    "            w1 = abs(bb1[2])\n",
    "            h1 = abs(bb1[3])\n",
    "            \n",
    "            bb2 = ast.literal_eval(your_list[i][4])\n",
    "            bb2 = [int(n) for n in bb2]\n",
    "            \n",
    "            x2 = abs(bb2[0])\n",
    "            y2 = abs(bb2[1])\n",
    "            w2 = abs(bb2[2])\n",
    "            h2 = abs(bb2[3])\n",
    "            \n",
    "            image = Union_WB_B_Seperate(height,width,x1,y1,h1,w1,x2,y2,h2,w2)\n",
    "            #print(image.shape)\n",
    "            image = cv2.resize(image.copy(), (size, size))\n",
    "            image = img_to_array(image.copy())\n",
    "            #update our corresponding batches lists\n",
    "            images.append(image)\n",
    "            i += 1\n",
    "\n",
    "        images = np.array(images, dtype=\"float\") /255.0\n",
    "        labels = np.array(labels)\n",
    "        labels = mlb.transform(labels)\n",
    "        # yield the batch to the calling function\n",
    "        yield (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mlb_multilabel(dir_out,TRAIN_CSV,TEST_CSV,VAL_CSV):\n",
    "    \n",
    "    labels = []\n",
    "    testLabels = []\n",
    "    validLabels = []\n",
    "    NUM_TRAIN_IMAGES = 0\n",
    "    NUM_TEST_IMAGES = 0\n",
    "    NUM_VAL_IMAGES = 0\n",
    "    #Open training file\n",
    "    with open(TRAIN_CSV, 'r') as f2:\n",
    "        reader = csv.reader(f2)\n",
    "        your_list = list(reader)\n",
    "    f2.close()\n",
    "    #Add all labels to the train label list\n",
    "    for i in range(len(your_list)):\n",
    "        x = ast.literal_eval(your_list[i][0])\n",
    "        x = [n.strip() for n in x]\n",
    "        labels.append(x)\n",
    "        NUM_TRAIN_IMAGES += 1\n",
    "        \n",
    "    #Repeat for test and valid\n",
    "    with open(TEST_CSV, 'r') as f3:\n",
    "        reader = csv.reader(f3)\n",
    "        your_list = list(reader)\n",
    "    f3.close()\n",
    "    \n",
    "    for i in range(len(your_list)):\n",
    "        x = ast.literal_eval(your_list[i][0])\n",
    "        x = [n.strip() for n in x]\n",
    "        testLabels.append(x)\n",
    "        NUM_TEST_IMAGES += 1\n",
    "\n",
    "    with open(VAL_CSV, 'r') as f4:\n",
    "        reader = csv.reader(f4)\n",
    "        your_list = list(reader)\n",
    "    f4.close()\n",
    "\n",
    "    for i in range(len(your_list)):\n",
    "        x = ast.literal_eval(your_list[i][0])\n",
    "        x = [n.strip() for n in x]\n",
    "        validLabels.append(x)\n",
    "        NUM_VAL_IMAGES += 1\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(labels)\n",
    "    testLabels = mlb.fit_transform(testLabels)\n",
    "    validLabels = mlb.fit_transform(validLabels)\n",
    "    \n",
    "    output_dir = \"pickle_models/\"+dir_out\n",
    "    # save the multi-label binarizer to disk\n",
    "    print(\"[INFO] serializing label binarizer...\")\n",
    "    f = open(output_dir, \"wb\")\n",
    "    f.write(pickle.dumps(mlb))\n",
    "    f.close()\n",
    "    \n",
    "    return testLabels,NUM_TRAIN_IMAGES,NUM_TEST_IMAGES,NUM_VAL_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_multi(model_type,activation_type,shape,name,trainable,NUM_EPOCHS,learning_rate,weights,mlb,TRAIN_CSV,Val_CSV,BS,NUM_TRAIN_IMAGES,NUM_VAL_IMAGES):\n",
    "    # initialize both the training and testing image generators\n",
    "    trainGen = csv_image_generator_multilabel(shape,TRAIN_CSV, BS, mlb,\n",
    "    mode=\"train\", aug=None)\n",
    "    valGen = csv_image_generator_multilabel(shape,Val_CSV, BS, mlb,\n",
    "    mode=\"train\", aug=None)\n",
    "    \n",
    "    if model_type == \"VGG16\":\n",
    "        if trainable == True:\n",
    "            model = build_trainable_VGG16(len(mlb.classes_),shape,activation_type)\n",
    "        elif trainable == False:\n",
    "            model = build_nottrainable_VGG16(len(mlb.classes_),shape,activation_type)\n",
    "    elif model_type == \"SmallVGG\":\n",
    "        model = build_smallvgg(len(mlb.classes_),shape,activation_type)\n",
    "    else:\n",
    "        print(\"FAILURE TO FIND MODEL TYPE\")\n",
    "        \n",
    "    if weights != None:\n",
    "        model.load_weights(weights)\n",
    "    \n",
    "    #Using binary cross entropy \n",
    "    opt = Adam(lr=learning_rate, decay=learning_rate / NUM_EPOCHS)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "        metrics=['categorical_accuracy'])\n",
    "    \n",
    "    # train the network\n",
    "    print(\"[INFO] training w/ generator...\")\n",
    "    H = model.fit_generator(\n",
    "        trainGen,\n",
    "        steps_per_epoch=NUM_TRAIN_IMAGES // BS,\n",
    "        validation_data=valGen,\n",
    "        validation_steps=NUM_VAL_IMAGES // BS,\n",
    "        epochs=NUM_EPOCHS)\n",
    "    print(\"[INFO] plotting...\")\n",
    "    plot_name = \"plots/\"+name + \"_plot.png\"\n",
    "    # plot the training loss and accuracy\n",
    "    N = NUM_EPOCHS\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"categorical_accuracy\"], label=\"categorical_accuracy\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_categorical_accuracy\"], label=\"val_categorical_accuracy\")\n",
    "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(plot_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(shape,report_name,mlb,BS,model,NUM_TEST_IMAGES,testLabels,TEST_CSV):\n",
    "    # re-initialize our testing data generator, this time for evaluating\n",
    "    testGen = csv_image_generator_multilabel(shape,TEST_CSV, BS, mlb,\n",
    "        mode=\"eval\", aug=None)\n",
    "    # make predictions on the testing images, finding the index of the\n",
    "    # label with the corresponding largest predicted probability\n",
    "    predIdxs = model.predict_generator(testGen,\n",
    "        steps=(NUM_TEST_IMAGES // BS) + 1)\n",
    "    predIdxs = np.argmax(predIdxs, axis=1)\n",
    "    \n",
    "    print(\"[INFO] evaluating network...\")\n",
    "    #print(classification_report(testLabels.argmax(axis=1), predIdxs,\n",
    "    #target_names=mlb.classes_))\n",
    "\n",
    "    report = classification_report(testLabels.argmax(axis=1), predIdxs, target_names=mlb.classes_)\n",
    "    write_name = \"reports/\"+report_name+\"_report.csv\"\n",
    "    lines = report.split('\\n')\n",
    "    with open(write_name,\"a\",newline=\"\") as f7: \n",
    "        for line in lines:\n",
    "            f7.write(line)\n",
    "            f7.write('\\n')\n",
    "    f7.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def run_models():    \n",
    "    BS = 32\n",
    "    Learning_rate_1 = 0.001\n",
    "    Learning_rate_2 = 0.00001\n",
    "    shape = 224\n",
    "    NUM_EPOCHS = 5\n",
    "    EPOCHS = 5\n",
    "    \n",
    "    for i in range(10):\n",
    "        print(\"[INFO] Starting to Train network : \",i)\n",
    "        TRAIN_CSV = \"TTV/Training_data_\"+str(i)+\".csv\"\n",
    "        TEST_CSV = \"TTV/Testing_data_\"+str(i)+\".csv\"\n",
    "        VAL_CSV = \"TTV/Validation_data_\"+str(i)+\".csv\"\n",
    "\n",
    "        NUM_TRAIN_IMAGES = 0\n",
    "        NUM_TEST_IMAGES = 0\n",
    "        NUM_VAL_IMAGES = 0\n",
    "        \n",
    "        output_dir = \"224_Small_Sigmoid_\"+str(i)+\".pickle\"\n",
    "        testLabels,NUM_TRAIN_IMAGES,NUM_TEST_IMAGES,NUM_VAL_IMAGES = extract_mlb_multilabel(output_dir,TRAIN_CSV,TEST_CSV,VAL_CSV)\n",
    "        pickle_dir = \"pickle_models/\"+output_dir\n",
    "        mlb = pickle.loads(open(pickle_dir, \"rb\").read())\n",
    "\n",
    "        name = \"224_Small_Sigmoid_\"+str(i)+\".h5\"\n",
    "        model = train_model_multi(\"SmallVGG\",\"sigmoid\",shape,name,True,NUM_EPOCHS,Learning_rate_1,None,mlb,TRAIN_CSV,VAL_CSV,BS,NUM_TRAIN_IMAGES,NUM_VAL_IMAGES)\n",
    "        print(\"[INFO] serializing network...\")\n",
    "        save_location = \"model/\"+name\n",
    "        model.save(save_location)\n",
    "        eval_name = \"224_Small_Sigmoid_\"+str(i)\n",
    "        evaluate_model(shape,eval_name,mlb,BS,model,NUM_TEST_IMAGES,testLabels,TEST_CSV)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting to Train network :  0\n",
      "[INFO] serializing label binarizer...\n",
      "[INFO] training w/ generator...\n",
      "Epoch 1/5\n",
      "1578/1578 [==============================] - 385s 244ms/step - loss: 0.2596 - categorical_accuracy: 0.2665 - val_loss: 0.2656 - val_categorical_accuracy: 0.2408\n",
      "Epoch 2/5\n",
      "   1/1578 [..............................] - ETA: 6:28 - loss: 0.1749 - categorical_accuracy: 0.5000"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_6_input to have 4 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-16dc5ce130ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-49e0b6daf59d>\u001b[0m in \u001b[0;36mrun_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"224_Small_Sigmoid_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SmallVGG\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLearning_rate_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmlb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRAIN_CSV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVAL_CSV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_TRAIN_IMAGES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_VAL_IMAGES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] serializing network...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0msave_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-e1891fbbf742>\u001b[0m in \u001b[0;36mtrain_model_multi\u001b[0;34m(model_type, activation_type, shape, name, trainable, NUM_EPOCHS, learning_rate, weights, mlb, TRAIN_CSV, Val_CSV, BS, NUM_TRAIN_IMAGES, NUM_VAL_IMAGES)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalGen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_VAL_IMAGES\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         epochs=NUM_EPOCHS)\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] plotting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mplot_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"plots/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_plot.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_6_input to have 4 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "run_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
